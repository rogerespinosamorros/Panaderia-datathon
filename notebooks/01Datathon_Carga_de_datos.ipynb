{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de Datos - Panadería Salvador\n",
        "\n",
        "## 1. Carga inicial de datos\n",
        "\n",
        "En este primer notebook del proyecto, vamos a realizar la **carga de datos brutos** de la Panadería Salvador. El objetivo es importar los archivos originales (ventas, productos, clientes, etc.), realizar una primera inspección básica y dejar los datos listos para el análisis exploratorio y el modelado posterior.\n",
        "\n",
        "**Pasos de este notebook:**\n",
        "- Descripción breve de los datos disponibles.\n",
        "- Carga de los archivos originales al entorno de trabajo.\n",
        "- Comprobación inicial de la integridad y estructura de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "> **Nota:** Todos los análisis, visualizaciones y modelos posteriores del proyecto partirán de esta carga inicial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ¿Por qué usamos SQLAlchemy y Polars?\n",
        "\n",
        "- **SQLAlchemy**: Permite conectar fácilmente a varias bases de datos y es más flexible y profesional que `mysql-connector-python`.\n",
        "- **Polars**: Es mucho más rápido y eficiente que pandas para el análisis y procesamiento de grandes volúmenes de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA6CHl-SEYwd",
        "outputId": "95941d1e-8f15-4c68-a728-5fc7b3a9a4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conexión OK: (1,)\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import create_engine, text, Table, MetaData, Column, Integer, String, Float, Date\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "import polars as pl\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# --- Credenciales ---\n",
        "user = os.getenv(\"DB_USER\")\n",
        "host = os.getenv(\"DB_HOST\")\n",
        "port = int(os.getenv(\"DB_PORT\", \"3306\"))\n",
        "password = os.getenv(\"DB_PASSWORD\")\n",
        "nombre_base_datos = os.getenv(\"DB_NAME\")\n",
        "\n",
        "# --- Motor SQL (con timeouts y ping) ---\n",
        "if 'engine' in globals():\n",
        "    try:\n",
        "        engine.dispose()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "engine = create_engine(\n",
        "    f\"mysql+pymysql://{user}:{password}@{host}:{port}/{nombre_base_datos}\",\n",
        "    pool_pre_ping=True,\n",
        "    pool_recycle=1800,\n",
        "    pool_size=5,\n",
        "    max_overflow=10,\n",
        "    connect_args={\"connect_timeout\": 10, \"read_timeout\": 120, \"write_timeout\": 120},\n",
        ")\n",
        "\n",
        "# Sanity check y “seguridad” (siempre se cae)\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"CREATE SCHEMA IF NOT EXISTS sandbox;\"))\n",
        "    con.execute(text(\"SET time_zone = 'Europe/Madrid';\"))\n",
        "    con.execute(text(\"SET SESSION sql_mode = CONCAT(@@sql_mode, ',ONLY_FULL_GROUP_BY');\"))\n",
        "\n",
        "with engine.connect() as con:\n",
        "    print(\"Conexión OK:\", con.execute(text(\"SELECT 1;\")).fetchone())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  \n",
        "\n",
        "DATA_RAW_DIR = r\"d:\\PersonalProjects\\Panadería Datathon\\data\\raw\"\n",
        "\n",
        "# He usado fastexcel para leer archivos excel sin usar Pandas (por probar)\n",
        "df_ventas = pl.read_excel(os.path.join(DATA_RAW_DIR, \"ArticulosPanaderia.xlsx\"))\n",
        "df_calendario = pl.read_excel(os.path.join(DATA_RAW_DIR, \"Calendario.xlsx\"))\n",
        "df_pedidos = pl.read_excel(os.path.join(DATA_RAW_DIR, \"CantidadPedida.xlsx\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✔ Asegurar nombres esperados (renombra si tus columnas difieren)\n",
        "# Ventas: FAMILIA, Tipo, FechaVenta, HoraVenta, Articulo, Cantidad, Precio, Importe\n",
        "expected_v_cols = {\"FAMILIA\",\"Tipo\",\"FechaVenta\",\"HoraVenta\",\"Articulo\",\"Cantidad\",\"Precio\",\"Importe\"}\n",
        "if set(df_ventas.columns) != expected_v_cols:\n",
        "    # ejemplo de renombres; ajusta si tus headers son distintos\n",
        "    ren = {}\n",
        "    for c in df_ventas.columns:\n",
        "        if c.lower() == \"familia\": ren[c] = \"FAMILIA\"\n",
        "        elif c.lower() == \"fecha\" or c.lower()==\"fechaventa\": ren[c] = \"FechaVenta\"\n",
        "        elif c.lower() == \"hora\" or c.lower()==\"horaventa\": ren[c] = \"HoraVenta\"\n",
        "        elif c.lower() == \"articulo\": ren[c] = \"Articulo\"\n",
        "        elif c.lower() == \"cantidad\": ren[c] = \"Cantidad\"\n",
        "        elif c.lower() == \"precio\": ren[c] = \"Precio\"\n",
        "        elif c.lower() == \"importe\": ren[c] = \"Importe\"\n",
        "        elif c.lower() == \"tipo\": ren[c] = \"Tipo\"\n",
        "    df_ventas = df_ventas.rename(ren)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Normalización robusta de tipos (Polars) ---\n",
        "\n",
        "# Ventas: FAMILIA, Tipo, FechaVenta, HoraVenta, Articulo, Cantidad, Precio, Importe\n",
        "df_ventas = (\n",
        "    df_ventas\n",
        "    .with_columns([\n",
        "        # pasa a texto y luego parsea -> funciona si venía ya como date o como string\n",
        "        pl.col(\"FechaVenta\").cast(pl.Utf8, strict=False).str.strptime(pl.Datetime, strict=False).alias(\"FechaVenta\"),\n",
        "        pl.col(\"HoraVenta\").cast(pl.Int64, strict=False).alias(\"HoraVenta\"),\n",
        "        pl.col(\"Articulo\").cast(pl.Int64, strict=False).alias(\"Articulo\"),\n",
        "        pl.col(\"Cantidad\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Cantidad\"),\n",
        "        pl.col(\"Precio\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Precio\"),\n",
        "        pl.col(\"Importe\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Importe\"),\n",
        "        pl.col(\"FAMILIA\").cast(pl.Utf8, strict=False).alias(\"FAMILIA\"),\n",
        "        pl.col(\"Tipo\").cast(pl.Utf8, strict=False).alias(\"Tipo\"),\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calendario: Fecha (date), Festivo (texto)\n",
        "df_calendario = (\n",
        "    df_calendario\n",
        "    .with_columns([\n",
        "        pl.col(\"Fecha\").cast(pl.Utf8, strict=False).str.strptime(pl.Date, strict=False).alias(\"Fecha\"),\n",
        "        pl.col(\"Festivo\").cast(pl.Utf8, strict=False).alias(\"Festivo\"),\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pedidos (si lo usas más tarde): Fecha, Articulo, Cantidad, Precio, Importe\n",
        "df_pedidos = (\n",
        "    df_pedidos\n",
        "    .with_columns([\n",
        "        pl.col(\"Fecha\").cast(pl.Utf8, strict=False).str.strptime(pl.Date, strict=False).alias(\"Fecha\"),\n",
        "        pl.col(\"Articulo\").cast(pl.Int64, strict=False).alias(\"Articulo\"),\n",
        "        pl.col(\"Cantidad\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Cantidad\"),\n",
        "        pl.col(\"Precio\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Precio\"),\n",
        "        pl.col(\"Importe\").cast(pl.Float64, strict=False).fill_null(0).alias(\"Importe\"),\n",
        "        pl.when(pl.col(\"Familia\").is_not_null()).then(pl.col(\"Familia\")).otherwise(pl.lit(\"\")).alias(\"Familia\"),\n",
        "        pl.when(pl.col(\"Tipo\").is_not_null()).then(pl.col(\"Tipo\")).otherwise(pl.lit(\"VENTA\")).alias(\"Tipo\"),\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dtypes ventas: [String, String, Datetime(time_unit='us', time_zone=None), Int64, Int64, Float64, Float64, Float64]\n",
            "dtypes calendario: [Date, String]\n",
            "dtypes pedidos: [String, String, Date, Int64, Float64, Float64, Float64]\n"
          ]
        }
      ],
      "source": [
        "# Compruebo los dtypes para confirmar\n",
        "print(\"dtypes ventas:\", df_ventas.dtypes)\n",
        "print(\"dtypes calendario:\", df_calendario.dtypes)\n",
        "print(\"dtypes pedidos:\", df_pedidos.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tablas base listas.\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import Table, MetaData, Column, Integer, String, Float, Date\n",
        "\n",
        "metadata = MetaData()\n",
        "\n",
        "rem_ventas = Table(\n",
        "    \"rem_ventas\", metadata,\n",
        "    Column(\"FAMILIA\", String(255)),\n",
        "    Column(\"Tipo\", String(255)),\n",
        "    Column(\"FechaVenta\", Date),\n",
        "    Column(\"HoraVenta\", Integer),\n",
        "    Column(\"Articulo\", String(255)),  # dejamos String para no chocar si ya existe\n",
        "    Column(\"Cantidad\", Float),\n",
        "    Column(\"Precio\", Float),\n",
        "    Column(\"Importe\", Float),\n",
        "    schema=\"sandbox\"\n",
        ")\n",
        "\n",
        "rem_calendario = Table(\n",
        "    \"rem_calendario\", metadata,\n",
        "    Column(\"Fecha\", Date),\n",
        "    Column(\"Festivo\", String(255)),\n",
        "    schema=\"sandbox\"\n",
        ")\n",
        "\n",
        "rem_pedidos = Table(\n",
        "    \"rem_pedidos\", metadata,\n",
        "    Column(\"Familia\", String(255)),\n",
        "    Column(\"Tipo\", String(255)),\n",
        "    Column(\"Fecha\", Date),\n",
        "    Column(\"Articulo\", String(255)),\n",
        "    Column(\"Cantidad\", Float),\n",
        "    Column(\"Precio\", Float),\n",
        "    Column(\"Importe\", Float),\n",
        "    schema=\"sandbox\"\n",
        ")\n",
        "\n",
        "metadata.create_all(engine)\n",
        "print(\"Tablas base listas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "FYW3bbG4F0um"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk 1 de rem_ventas (1000 filas) insertado\n",
            "Chunk 2 de rem_ventas (1000 filas) insertado\n",
            "Chunk 3 de rem_ventas (1000 filas) insertado\n",
            "Chunk 4 de rem_ventas (1000 filas) insertado\n",
            "Chunk 5 de rem_ventas (1000 filas) insertado\n",
            "Chunk 6 de rem_ventas (1000 filas) insertado\n",
            "Chunk 7 de rem_ventas (1000 filas) insertado\n",
            "Chunk 8 de rem_ventas (1000 filas) insertado\n",
            "Chunk 9 de rem_ventas (1000 filas) insertado\n",
            "Chunk 10 de rem_ventas (1000 filas) insertado\n",
            "Chunk 11 de rem_ventas (1000 filas) insertado\n",
            "Chunk 12 de rem_ventas (1000 filas) insertado\n",
            "Chunk 13 de rem_ventas (1000 filas) insertado\n",
            "Chunk 14 de rem_ventas (1000 filas) insertado\n",
            "Chunk 15 de rem_ventas (1000 filas) insertado\n",
            "Chunk 16 de rem_ventas (1000 filas) insertado\n",
            "Chunk 17 de rem_ventas (1000 filas) insertado\n",
            "Chunk 18 de rem_ventas (1000 filas) insertado\n",
            "Chunk 19 de rem_ventas (1000 filas) insertado\n",
            "Chunk 20 de rem_ventas (1000 filas) insertado\n",
            "Chunk 21 de rem_ventas (1000 filas) insertado\n",
            "Chunk 22 de rem_ventas (1000 filas) insertado\n",
            "Chunk 23 de rem_ventas (1000 filas) insertado\n",
            "Chunk 24 de rem_ventas (1000 filas) insertado\n",
            "Chunk 25 de rem_ventas (1000 filas) insertado\n",
            "Chunk 26 de rem_ventas (1000 filas) insertado\n",
            "Chunk 27 de rem_ventas (1000 filas) insertado\n",
            "Chunk 28 de rem_ventas (1000 filas) insertado\n",
            "Chunk 29 de rem_ventas (1000 filas) insertado\n",
            "Chunk 30 de rem_ventas (1000 filas) insertado\n",
            "Chunk 31 de rem_ventas (1000 filas) insertado\n",
            "Chunk 32 de rem_ventas (1000 filas) insertado\n",
            "Chunk 33 de rem_ventas (1000 filas) insertado\n",
            "Chunk 34 de rem_ventas (1000 filas) insertado\n",
            "Chunk 35 de rem_ventas (1000 filas) insertado\n",
            "Chunk 36 de rem_ventas (1000 filas) insertado\n",
            "Chunk 37 de rem_ventas (1000 filas) insertado\n",
            "Chunk 38 de rem_ventas (1000 filas) insertado\n",
            "Chunk 39 de rem_ventas (1000 filas) insertado\n",
            "Chunk 40 de rem_ventas (1000 filas) insertado\n",
            "Chunk 41 de rem_ventas (1000 filas) insertado\n",
            "Chunk 42 de rem_ventas (1000 filas) insertado\n",
            "Chunk 43 de rem_ventas (1000 filas) insertado\n",
            "Chunk 44 de rem_ventas (1000 filas) insertado\n",
            "Chunk 45 de rem_ventas (1000 filas) insertado\n",
            "Chunk 46 de rem_ventas (1000 filas) insertado\n",
            "Chunk 47 de rem_ventas (1000 filas) insertado\n",
            "Chunk 48 de rem_ventas (1000 filas) insertado\n",
            "Chunk 49 de rem_ventas (1000 filas) insertado\n",
            "Chunk 50 de rem_ventas (1000 filas) insertado\n",
            "Chunk 51 de rem_ventas (1000 filas) insertado\n",
            "Chunk 52 de rem_ventas (1000 filas) insertado\n",
            "Chunk 53 de rem_ventas (1000 filas) insertado\n",
            "Chunk 54 de rem_ventas (1000 filas) insertado\n",
            "Chunk 55 de rem_ventas (1000 filas) insertado\n",
            "Chunk 56 de rem_ventas (1000 filas) insertado\n",
            "Chunk 57 de rem_ventas (1000 filas) insertado\n",
            "Chunk 58 de rem_ventas (1000 filas) insertado\n",
            "Chunk 59 de rem_ventas (1000 filas) insertado\n",
            "Chunk 60 de rem_ventas (1000 filas) insertado\n",
            "Chunk 61 de rem_ventas (1000 filas) insertado\n",
            "Chunk 62 de rem_ventas (1000 filas) insertado\n",
            "Chunk 63 de rem_ventas (1000 filas) insertado\n",
            "Chunk 64 de rem_ventas (1000 filas) insertado\n",
            "Chunk 65 de rem_ventas (1000 filas) insertado\n",
            "Chunk 66 de rem_ventas (1000 filas) insertado\n",
            "Chunk 67 de rem_ventas (1000 filas) insertado\n",
            "Chunk 68 de rem_ventas (1000 filas) insertado\n",
            "Chunk 69 de rem_ventas (1000 filas) insertado\n",
            "Chunk 70 de rem_ventas (1000 filas) insertado\n",
            "Chunk 71 de rem_ventas (1000 filas) insertado\n",
            "Chunk 72 de rem_ventas (1000 filas) insertado\n",
            "Chunk 73 de rem_ventas (1000 filas) insertado\n",
            "Chunk 74 de rem_ventas (1000 filas) insertado\n",
            "Chunk 75 de rem_ventas (1000 filas) insertado\n",
            "Chunk 76 de rem_ventas (1000 filas) insertado\n",
            "Chunk 77 de rem_ventas (1000 filas) insertado\n",
            "Chunk 78 de rem_ventas (1000 filas) insertado\n",
            "Chunk 79 de rem_ventas (1000 filas) insertado\n",
            "Chunk 80 de rem_ventas (1000 filas) insertado\n",
            "Chunk 81 de rem_ventas (1000 filas) insertado\n",
            "Chunk 82 de rem_ventas (1000 filas) insertado\n",
            "Chunk 83 de rem_ventas (1000 filas) insertado\n",
            "Chunk 84 de rem_ventas (1000 filas) insertado\n",
            "Chunk 85 de rem_ventas (1000 filas) insertado\n",
            "Chunk 86 de rem_ventas (1000 filas) insertado\n",
            "Chunk 87 de rem_ventas (1000 filas) insertado\n",
            "Chunk 88 de rem_ventas (1000 filas) insertado\n",
            "Chunk 89 de rem_ventas (1000 filas) insertado\n",
            "Chunk 90 de rem_ventas (1000 filas) insertado\n",
            "Chunk 91 de rem_ventas (1000 filas) insertado\n",
            "Chunk 92 de rem_ventas (1000 filas) insertado\n",
            "Chunk 93 de rem_ventas (1000 filas) insertado\n",
            "Chunk 94 de rem_ventas (1000 filas) insertado\n",
            "Chunk 95 de rem_ventas (1000 filas) insertado\n",
            "Chunk 96 de rem_ventas (1000 filas) insertado\n",
            "Chunk 97 de rem_ventas (1000 filas) insertado\n",
            "Chunk 98 de rem_ventas (1000 filas) insertado\n",
            "Chunk 99 de rem_ventas (1000 filas) insertado\n",
            "Chunk 100 de rem_ventas (1000 filas) insertado\n",
            "Chunk 101 de rem_ventas (1000 filas) insertado\n",
            "Chunk 102 de rem_ventas (1000 filas) insertado\n",
            "Chunk 103 de rem_ventas (1000 filas) insertado\n",
            "Chunk 104 de rem_ventas (1000 filas) insertado\n",
            "Chunk 105 de rem_ventas (1000 filas) insertado\n",
            "Chunk 106 de rem_ventas (1000 filas) insertado\n",
            "Chunk 107 de rem_ventas (1000 filas) insertado\n",
            "Chunk 108 de rem_ventas (1000 filas) insertado\n",
            "Chunk 109 de rem_ventas (1000 filas) insertado\n",
            "Chunk 110 de rem_ventas (1000 filas) insertado\n",
            "Chunk 111 de rem_ventas (1000 filas) insertado\n",
            "Chunk 112 de rem_ventas (1000 filas) insertado\n",
            "Chunk 113 de rem_ventas (1000 filas) insertado\n",
            "Chunk 114 de rem_ventas (1000 filas) insertado\n",
            "Chunk 115 de rem_ventas (1000 filas) insertado\n",
            "Chunk 116 de rem_ventas (1000 filas) insertado\n",
            "Chunk 117 de rem_ventas (1000 filas) insertado\n",
            "Chunk 118 de rem_ventas (1000 filas) insertado\n",
            "Chunk 119 de rem_ventas (1000 filas) insertado\n",
            "Chunk 120 de rem_ventas (1000 filas) insertado\n",
            "Chunk 121 de rem_ventas (1000 filas) insertado\n",
            "Chunk 122 de rem_ventas (1000 filas) insertado\n",
            "Chunk 123 de rem_ventas (1000 filas) insertado\n",
            "Chunk 124 de rem_ventas (1000 filas) insertado\n",
            "Chunk 125 de rem_ventas (1000 filas) insertado\n",
            "Chunk 126 de rem_ventas (1000 filas) insertado\n",
            "Chunk 127 de rem_ventas (1000 filas) insertado\n",
            "Chunk 128 de rem_ventas (1000 filas) insertado\n",
            "Chunk 129 de rem_ventas (1000 filas) insertado\n",
            "Chunk 130 de rem_ventas (1000 filas) insertado\n",
            "Chunk 131 de rem_ventas (1000 filas) insertado\n",
            "Chunk 132 de rem_ventas (1000 filas) insertado\n",
            "Chunk 133 de rem_ventas (1000 filas) insertado\n",
            "Chunk 134 de rem_ventas (1000 filas) insertado\n",
            "Chunk 135 de rem_ventas (1000 filas) insertado\n",
            "Chunk 136 de rem_ventas (1000 filas) insertado\n",
            "Chunk 137 de rem_ventas (1000 filas) insertado\n",
            "Chunk 138 de rem_ventas (1000 filas) insertado\n",
            "Chunk 139 de rem_ventas (1000 filas) insertado\n",
            "Chunk 140 de rem_ventas (1000 filas) insertado\n",
            "Chunk 141 de rem_ventas (1000 filas) insertado\n",
            "Chunk 142 de rem_ventas (1000 filas) insertado\n",
            "Chunk 143 de rem_ventas (1000 filas) insertado\n",
            "Chunk 144 de rem_ventas (1000 filas) insertado\n",
            "Chunk 145 de rem_ventas (1000 filas) insertado\n",
            "Chunk 146 de rem_ventas (1000 filas) insertado\n",
            "Chunk 147 de rem_ventas (1000 filas) insertado\n",
            "Chunk 148 de rem_ventas (1000 filas) insertado\n",
            "Chunk 149 de rem_ventas (1000 filas) insertado\n",
            "Chunk 150 de rem_ventas (1000 filas) insertado\n",
            "Chunk 151 de rem_ventas (1000 filas) insertado\n",
            "Chunk 152 de rem_ventas (1000 filas) insertado\n",
            "Chunk 153 de rem_ventas (1000 filas) insertado\n",
            "Chunk 154 de rem_ventas (1000 filas) insertado\n",
            "Chunk 155 de rem_ventas (1000 filas) insertado\n",
            "Chunk 156 de rem_ventas (1000 filas) insertado\n",
            "Chunk 157 de rem_ventas (1000 filas) insertado\n",
            "Chunk 158 de rem_ventas (1000 filas) insertado\n",
            "Chunk 159 de rem_ventas (1000 filas) insertado\n",
            "Chunk 160 de rem_ventas (1000 filas) insertado\n",
            "Chunk 161 de rem_ventas (1000 filas) insertado\n",
            "Chunk 162 de rem_ventas (1000 filas) insertado\n",
            "Chunk 163 de rem_ventas (1000 filas) insertado\n",
            "Chunk 164 de rem_ventas (1000 filas) insertado\n",
            "Chunk 165 de rem_ventas (1000 filas) insertado\n",
            "Chunk 166 de rem_ventas (1000 filas) insertado\n",
            "Chunk 167 de rem_ventas (1000 filas) insertado\n",
            "Chunk 168 de rem_ventas (1000 filas) insertado\n",
            "Chunk 169 de rem_ventas (1000 filas) insertado\n",
            "Chunk 170 de rem_ventas (1000 filas) insertado\n",
            "Chunk 171 de rem_ventas (1000 filas) insertado\n",
            "Chunk 172 de rem_ventas (1000 filas) insertado\n",
            "Chunk 173 de rem_ventas (1000 filas) insertado\n",
            "Chunk 174 de rem_ventas (1000 filas) insertado\n",
            "Chunk 175 de rem_ventas (1000 filas) insertado\n",
            "Chunk 176 de rem_ventas (1000 filas) insertado\n",
            "Chunk 177 de rem_ventas (1000 filas) insertado\n",
            "Chunk 178 de rem_ventas (1000 filas) insertado\n",
            "Chunk 179 de rem_ventas (1000 filas) insertado\n",
            "Chunk 180 de rem_ventas (1000 filas) insertado\n",
            "Chunk 181 de rem_ventas (1000 filas) insertado\n",
            "Chunk 182 de rem_ventas (1000 filas) insertado\n",
            "Chunk 183 de rem_ventas (1000 filas) insertado\n",
            "Chunk 184 de rem_ventas (1000 filas) insertado\n",
            "Chunk 185 de rem_ventas (1000 filas) insertado\n",
            "Chunk 186 de rem_ventas (1000 filas) insertado\n",
            "Chunk 187 de rem_ventas (1000 filas) insertado\n",
            "Chunk 188 de rem_ventas (1000 filas) insertado\n",
            "Chunk 189 de rem_ventas (1000 filas) insertado\n",
            "Chunk 190 de rem_ventas (1000 filas) insertado\n",
            "Chunk 191 de rem_ventas (1000 filas) insertado\n",
            "Chunk 192 de rem_ventas (1000 filas) insertado\n",
            "Chunk 193 de rem_ventas (1000 filas) insertado\n",
            "Chunk 194 de rem_ventas (1000 filas) insertado\n",
            "Chunk 195 de rem_ventas (1000 filas) insertado\n",
            "Chunk 196 de rem_ventas (1000 filas) insertado\n",
            "Chunk 197 de rem_ventas (1000 filas) insertado\n",
            "Chunk 198 de rem_ventas (1000 filas) insertado\n",
            "Chunk 199 de rem_ventas (1000 filas) insertado\n",
            "Chunk 200 de rem_ventas (1000 filas) insertado\n",
            "Chunk 201 de rem_ventas (1000 filas) insertado\n",
            "Chunk 202 de rem_ventas (1000 filas) insertado\n",
            "Chunk 203 de rem_ventas (1000 filas) insertado\n",
            "Chunk 204 de rem_ventas (1000 filas) insertado\n",
            "Chunk 205 de rem_ventas (1000 filas) insertado\n",
            "Chunk 206 de rem_ventas (1000 filas) insertado\n",
            "Chunk 207 de rem_ventas (1000 filas) insertado\n",
            "Chunk 208 de rem_ventas (1000 filas) insertado\n",
            "Chunk 209 de rem_ventas (1000 filas) insertado\n",
            "Chunk 210 de rem_ventas (1000 filas) insertado\n",
            "Chunk 211 de rem_ventas (1000 filas) insertado\n",
            "Chunk 212 de rem_ventas (1000 filas) insertado\n",
            "Chunk 213 de rem_ventas (1000 filas) insertado\n",
            "Chunk 214 de rem_ventas (1000 filas) insertado\n",
            "Chunk 215 de rem_ventas (1000 filas) insertado\n",
            "Chunk 216 de rem_ventas (1000 filas) insertado\n",
            "Chunk 217 de rem_ventas (1000 filas) insertado\n",
            "Chunk 218 de rem_ventas (1000 filas) insertado\n",
            "Chunk 219 de rem_ventas (1000 filas) insertado\n",
            "Chunk 220 de rem_ventas (1000 filas) insertado\n",
            "Chunk 221 de rem_ventas (1000 filas) insertado\n",
            "Chunk 222 de rem_ventas (1000 filas) insertado\n",
            "Chunk 223 de rem_ventas (1000 filas) insertado\n",
            "Chunk 224 de rem_ventas (1000 filas) insertado\n",
            "Chunk 225 de rem_ventas (1000 filas) insertado\n",
            "Chunk 226 de rem_ventas (1000 filas) insertado\n",
            "Chunk 227 de rem_ventas (1000 filas) insertado\n",
            "Chunk 228 de rem_ventas (1000 filas) insertado\n",
            "Chunk 229 de rem_ventas (1000 filas) insertado\n",
            "Chunk 230 de rem_ventas (1000 filas) insertado\n",
            "Chunk 231 de rem_ventas (1000 filas) insertado\n",
            "Chunk 232 de rem_ventas (1000 filas) insertado\n",
            "Chunk 233 de rem_ventas (1000 filas) insertado\n",
            "Chunk 234 de rem_ventas (1000 filas) insertado\n",
            "Chunk 235 de rem_ventas (1000 filas) insertado\n",
            "Chunk 236 de rem_ventas (1000 filas) insertado\n",
            "Chunk 237 de rem_ventas (1000 filas) insertado\n",
            "Chunk 238 de rem_ventas (1000 filas) insertado\n",
            "Chunk 239 de rem_ventas (1000 filas) insertado\n",
            "Chunk 240 de rem_ventas (1000 filas) insertado\n",
            "Chunk 241 de rem_ventas (1000 filas) insertado\n",
            "Chunk 242 de rem_ventas (1000 filas) insertado\n",
            "Chunk 243 de rem_ventas (1000 filas) insertado\n",
            "Chunk 244 de rem_ventas (1000 filas) insertado\n",
            "Chunk 245 de rem_ventas (1000 filas) insertado\n",
            "Chunk 246 de rem_ventas (1000 filas) insertado\n",
            "Chunk 247 de rem_ventas (1000 filas) insertado\n",
            "Chunk 248 de rem_ventas (1000 filas) insertado\n",
            "Chunk 249 de rem_ventas (1000 filas) insertado\n",
            "Chunk 250 de rem_ventas (1000 filas) insertado\n",
            "Chunk 251 de rem_ventas (1000 filas) insertado\n",
            "Chunk 252 de rem_ventas (1000 filas) insertado\n",
            "Chunk 253 de rem_ventas (1000 filas) insertado\n",
            "Chunk 254 de rem_ventas (1000 filas) insertado\n",
            "Chunk 255 de rem_ventas (1000 filas) insertado\n",
            "Chunk 256 de rem_ventas (1000 filas) insertado\n",
            "Chunk 257 de rem_ventas (1000 filas) insertado\n",
            "Chunk 258 de rem_ventas (1000 filas) insertado\n",
            "Chunk 259 de rem_ventas (1000 filas) insertado\n",
            "Chunk 260 de rem_ventas (1000 filas) insertado\n",
            "Chunk 261 de rem_ventas (1000 filas) insertado\n",
            "Chunk 262 de rem_ventas (1000 filas) insertado\n",
            "Chunk 263 de rem_ventas (1000 filas) insertado\n",
            "Chunk 264 de rem_ventas (1000 filas) insertado\n",
            "Chunk 265 de rem_ventas (1000 filas) insertado\n",
            "Chunk 266 de rem_ventas (1000 filas) insertado\n",
            "Chunk 267 de rem_ventas (1000 filas) insertado\n",
            "Chunk 268 de rem_ventas (1000 filas) insertado\n",
            "Chunk 269 de rem_ventas (1000 filas) insertado\n",
            "Chunk 270 de rem_ventas (1000 filas) insertado\n",
            "Chunk 271 de rem_ventas (1000 filas) insertado\n",
            "Chunk 272 de rem_ventas (1000 filas) insertado\n",
            "Chunk 273 de rem_ventas (1000 filas) insertado\n",
            "Chunk 274 de rem_ventas (1000 filas) insertado\n",
            "Chunk 275 de rem_ventas (1000 filas) insertado\n",
            "Chunk 276 de rem_ventas (1000 filas) insertado\n",
            "Chunk 277 de rem_ventas (1000 filas) insertado\n",
            "Chunk 278 de rem_ventas (1000 filas) insertado\n",
            "Chunk 279 de rem_ventas (1000 filas) insertado\n",
            "Chunk 280 de rem_ventas (1000 filas) insertado\n",
            "Chunk 281 de rem_ventas (1000 filas) insertado\n",
            "Chunk 282 de rem_ventas (1000 filas) insertado\n",
            "Chunk 283 de rem_ventas (1000 filas) insertado\n",
            "Chunk 284 de rem_ventas (1000 filas) insertado\n",
            "Chunk 285 de rem_ventas (1000 filas) insertado\n",
            "Chunk 286 de rem_ventas (1000 filas) insertado\n",
            "Chunk 287 de rem_ventas (1000 filas) insertado\n",
            "Chunk 288 de rem_ventas (1000 filas) insertado\n",
            "Chunk 289 de rem_ventas (1000 filas) insertado\n",
            "Chunk 290 de rem_ventas (1000 filas) insertado\n",
            "Chunk 291 de rem_ventas (1000 filas) insertado\n",
            "Chunk 292 de rem_ventas (1000 filas) insertado\n",
            "Chunk 293 de rem_ventas (1000 filas) insertado\n",
            "Chunk 294 de rem_ventas (1000 filas) insertado\n",
            "Chunk 295 de rem_ventas (1000 filas) insertado\n",
            "Chunk 296 de rem_ventas (1000 filas) insertado\n",
            "Chunk 297 de rem_ventas (1000 filas) insertado\n",
            "Chunk 298 de rem_ventas (1000 filas) insertado\n",
            "Chunk 299 de rem_ventas (1000 filas) insertado\n",
            "Chunk 300 de rem_ventas (1000 filas) insertado\n",
            "Chunk 301 de rem_ventas (1000 filas) insertado\n",
            "Chunk 302 de rem_ventas (1000 filas) insertado\n",
            "Chunk 303 de rem_ventas (1000 filas) insertado\n",
            "Chunk 304 de rem_ventas (1000 filas) insertado\n",
            "Chunk 305 de rem_ventas (1000 filas) insertado\n",
            "Chunk 306 de rem_ventas (1000 filas) insertado\n",
            "Chunk 307 de rem_ventas (1000 filas) insertado\n",
            "Chunk 308 de rem_ventas (1000 filas) insertado\n",
            "Chunk 309 de rem_ventas (1000 filas) insertado\n",
            "Chunk 310 de rem_ventas (1000 filas) insertado\n",
            "Chunk 311 de rem_ventas (1000 filas) insertado\n",
            "Chunk 312 de rem_ventas (1000 filas) insertado\n",
            "Chunk 313 de rem_ventas (1000 filas) insertado\n",
            "Chunk 314 de rem_ventas (1000 filas) insertado\n",
            "Chunk 315 de rem_ventas (1000 filas) insertado\n",
            "Chunk 316 de rem_ventas (1000 filas) insertado\n",
            "Chunk 317 de rem_ventas (1000 filas) insertado\n",
            "Chunk 318 de rem_ventas (1000 filas) insertado\n",
            "Chunk 319 de rem_ventas (1000 filas) insertado\n",
            "Chunk 320 de rem_ventas (1000 filas) insertado\n",
            "Chunk 321 de rem_ventas (1000 filas) insertado\n",
            "Chunk 322 de rem_ventas (1000 filas) insertado\n",
            "Chunk 323 de rem_ventas (1000 filas) insertado\n",
            "Chunk 324 de rem_ventas (1000 filas) insertado\n",
            "Chunk 325 de rem_ventas (1000 filas) insertado\n",
            "Chunk 326 de rem_ventas (1000 filas) insertado\n",
            "Chunk 327 de rem_ventas (1000 filas) insertado\n",
            "Chunk 328 de rem_ventas (1000 filas) insertado\n",
            "Chunk 329 de rem_ventas (1000 filas) insertado\n",
            "Chunk 330 de rem_ventas (1000 filas) insertado\n",
            "Chunk 331 de rem_ventas (1000 filas) insertado\n",
            "Chunk 332 de rem_ventas (1000 filas) insertado\n",
            "Chunk 333 de rem_ventas (1000 filas) insertado\n",
            "Chunk 334 de rem_ventas (1000 filas) insertado\n",
            "Chunk 335 de rem_ventas (1000 filas) insertado\n",
            "Chunk 336 de rem_ventas (1000 filas) insertado\n",
            "Chunk 337 de rem_ventas (1000 filas) insertado\n",
            "Chunk 338 de rem_ventas (1000 filas) insertado\n",
            "Chunk 339 de rem_ventas (1000 filas) insertado\n",
            "Chunk 340 de rem_ventas (1000 filas) insertado\n",
            "Chunk 341 de rem_ventas (1000 filas) insertado\n",
            "Chunk 342 de rem_ventas (1000 filas) insertado\n",
            "Chunk 343 de rem_ventas (1000 filas) insertado\n",
            "Chunk 344 de rem_ventas (1000 filas) insertado\n",
            "Chunk 345 de rem_ventas (1000 filas) insertado\n",
            "Chunk 346 de rem_ventas (1000 filas) insertado\n",
            "Chunk 347 de rem_ventas (1000 filas) insertado\n",
            "Chunk 348 de rem_ventas (1000 filas) insertado\n",
            "Chunk 349 de rem_ventas (1000 filas) insertado\n",
            "Chunk 350 de rem_ventas (1000 filas) insertado\n",
            "Chunk 351 de rem_ventas (1000 filas) insertado\n",
            "Chunk 352 de rem_ventas (1000 filas) insertado\n",
            "Chunk 353 de rem_ventas (1000 filas) insertado\n",
            "Chunk 354 de rem_ventas (1000 filas) insertado\n",
            "Chunk 355 de rem_ventas (1000 filas) insertado\n",
            "Chunk 356 de rem_ventas (1000 filas) insertado\n",
            "Chunk 357 de rem_ventas (1000 filas) insertado\n",
            "Chunk 358 de rem_ventas (1000 filas) insertado\n",
            "Chunk 359 de rem_ventas (1000 filas) insertado\n",
            "Chunk 360 de rem_ventas (1000 filas) insertado\n",
            "Chunk 361 de rem_ventas (1000 filas) insertado\n",
            "Chunk 362 de rem_ventas (1000 filas) insertado\n",
            "Chunk 363 de rem_ventas (1000 filas) insertado\n",
            "Chunk 364 de rem_ventas (1000 filas) insertado\n",
            "Chunk 365 de rem_ventas (1000 filas) insertado\n",
            "Chunk 366 de rem_ventas (1000 filas) insertado\n",
            "Chunk 367 de rem_ventas (1000 filas) insertado\n",
            "Chunk 368 de rem_ventas (1000 filas) insertado\n",
            "Chunk 369 de rem_ventas (1000 filas) insertado\n",
            "Chunk 370 de rem_ventas (1000 filas) insertado\n",
            "Chunk 371 de rem_ventas (1000 filas) insertado\n",
            "Chunk 372 de rem_ventas (1000 filas) insertado\n",
            "Chunk 373 de rem_ventas (1000 filas) insertado\n",
            "Chunk 374 de rem_ventas (1000 filas) insertado\n",
            "Chunk 375 de rem_ventas (1000 filas) insertado\n",
            "Chunk 376 de rem_ventas (1000 filas) insertado\n",
            "Chunk 377 de rem_ventas (1000 filas) insertado\n",
            "Chunk 378 de rem_ventas (1000 filas) insertado\n",
            "Chunk 379 de rem_ventas (1000 filas) insertado\n",
            "Chunk 380 de rem_ventas (1000 filas) insertado\n",
            "Chunk 381 de rem_ventas (1000 filas) insertado\n",
            "Chunk 382 de rem_ventas (1000 filas) insertado\n",
            "Chunk 383 de rem_ventas (1000 filas) insertado\n",
            "Chunk 384 de rem_ventas (1000 filas) insertado\n",
            "Chunk 385 de rem_ventas (1000 filas) insertado\n",
            "Chunk 386 de rem_ventas (1000 filas) insertado\n",
            "Chunk 387 de rem_ventas (1000 filas) insertado\n",
            "Chunk 388 de rem_ventas (1000 filas) insertado\n",
            "Chunk 389 de rem_ventas (1000 filas) insertado\n",
            "Chunk 390 de rem_ventas (1000 filas) insertado\n",
            "Chunk 391 de rem_ventas (1000 filas) insertado\n",
            "Chunk 392 de rem_ventas (1000 filas) insertado\n",
            "Chunk 393 de rem_ventas (1000 filas) insertado\n",
            "Chunk 394 de rem_ventas (1000 filas) insertado\n",
            "Chunk 395 de rem_ventas (1000 filas) insertado\n",
            "Chunk 396 de rem_ventas (1000 filas) insertado\n",
            "Chunk 397 de rem_ventas (1000 filas) insertado\n",
            "Chunk 398 de rem_ventas (1000 filas) insertado\n",
            "Chunk 399 de rem_ventas (1000 filas) insertado\n",
            "Chunk 400 de rem_ventas (1000 filas) insertado\n",
            "Chunk 401 de rem_ventas (1000 filas) insertado\n",
            "Chunk 402 de rem_ventas (1000 filas) insertado\n",
            "Chunk 403 de rem_ventas (1000 filas) insertado\n",
            "Chunk 404 de rem_ventas (1000 filas) insertado\n",
            "Chunk 405 de rem_ventas (1000 filas) insertado\n",
            "Chunk 406 de rem_ventas (1000 filas) insertado\n",
            "Chunk 407 de rem_ventas (1000 filas) insertado\n",
            "Chunk 408 de rem_ventas (1000 filas) insertado\n",
            "Chunk 409 de rem_ventas (1000 filas) insertado\n",
            "Chunk 410 de rem_ventas (1000 filas) insertado\n",
            "Chunk 411 de rem_ventas (1000 filas) insertado\n",
            "Chunk 412 de rem_ventas (1000 filas) insertado\n",
            "Chunk 413 de rem_ventas (1000 filas) insertado\n",
            "Chunk 414 de rem_ventas (1000 filas) insertado\n",
            "Chunk 415 de rem_ventas (1000 filas) insertado\n",
            "Chunk 416 de rem_ventas (1000 filas) insertado\n",
            "Chunk 417 de rem_ventas (1000 filas) insertado\n",
            "Chunk 418 de rem_ventas (1000 filas) insertado\n",
            "Chunk 419 de rem_ventas (1000 filas) insertado\n",
            "Chunk 420 de rem_ventas (1000 filas) insertado\n",
            "Chunk 421 de rem_ventas (1000 filas) insertado\n",
            "Chunk 422 de rem_ventas (1000 filas) insertado\n",
            "Chunk 423 de rem_ventas (1000 filas) insertado\n",
            "Chunk 424 de rem_ventas (1000 filas) insertado\n",
            "Chunk 425 de rem_ventas (1000 filas) insertado\n",
            "Chunk 426 de rem_ventas (1000 filas) insertado\n",
            "Chunk 427 de rem_ventas (1000 filas) insertado\n",
            "Chunk 428 de rem_ventas (1000 filas) insertado\n",
            "Chunk 429 de rem_ventas (1000 filas) insertado\n",
            "Chunk 430 de rem_ventas (1000 filas) insertado\n",
            "Chunk 431 de rem_ventas (1000 filas) insertado\n",
            "Chunk 432 de rem_ventas (1000 filas) insertado\n",
            "Chunk 433 de rem_ventas (1000 filas) insertado\n",
            "Chunk 434 de rem_ventas (1000 filas) insertado\n",
            "Chunk 435 de rem_ventas (1000 filas) insertado\n",
            "Chunk 436 de rem_ventas (1000 filas) insertado\n",
            "Chunk 437 de rem_ventas (1000 filas) insertado\n",
            "Chunk 438 de rem_ventas (1000 filas) insertado\n",
            "Chunk 439 de rem_ventas (1000 filas) insertado\n",
            "Chunk 440 de rem_ventas (1000 filas) insertado\n",
            "Chunk 441 de rem_ventas (1000 filas) insertado\n",
            "Chunk 442 de rem_ventas (1000 filas) insertado\n",
            "Chunk 443 de rem_ventas (1000 filas) insertado\n",
            "Chunk 444 de rem_ventas (1000 filas) insertado\n",
            "Chunk 445 de rem_ventas (1000 filas) insertado\n",
            "Chunk 446 de rem_ventas (1000 filas) insertado\n",
            "Chunk 447 de rem_ventas (1000 filas) insertado\n",
            "Chunk 448 de rem_ventas (1000 filas) insertado\n",
            "Chunk 449 de rem_ventas (1000 filas) insertado\n",
            "Chunk 450 de rem_ventas (1000 filas) insertado\n",
            "Chunk 451 de rem_ventas (1000 filas) insertado\n",
            "Chunk 452 de rem_ventas (1000 filas) insertado\n",
            "Chunk 453 de rem_ventas (1000 filas) insertado\n",
            "Chunk 454 de rem_ventas (1000 filas) insertado\n",
            "Chunk 455 de rem_ventas (1000 filas) insertado\n",
            "Chunk 456 de rem_ventas (1000 filas) insertado\n",
            "Chunk 457 de rem_ventas (1000 filas) insertado\n",
            "Chunk 458 de rem_ventas (1000 filas) insertado\n",
            "Chunk 459 de rem_ventas (1000 filas) insertado\n",
            "Chunk 460 de rem_ventas (1000 filas) insertado\n",
            "Chunk 461 de rem_ventas (1000 filas) insertado\n",
            "Chunk 462 de rem_ventas (1000 filas) insertado\n",
            "Chunk 463 de rem_ventas (1000 filas) insertado\n",
            "Chunk 464 de rem_ventas (1000 filas) insertado\n",
            "Chunk 465 de rem_ventas (1000 filas) insertado\n",
            "Chunk 466 de rem_ventas (1000 filas) insertado\n",
            "Chunk 467 de rem_ventas (1000 filas) insertado\n",
            "Chunk 468 de rem_ventas (1000 filas) insertado\n",
            "Chunk 469 de rem_ventas (1000 filas) insertado\n",
            "Chunk 470 de rem_ventas (1000 filas) insertado\n",
            "Chunk 471 de rem_ventas (1000 filas) insertado\n",
            "Chunk 472 de rem_ventas (1000 filas) insertado\n",
            "Chunk 473 de rem_ventas (1000 filas) insertado\n",
            "Chunk 474 de rem_ventas (1000 filas) insertado\n",
            "Chunk 475 de rem_ventas (1000 filas) insertado\n",
            "Chunk 476 de rem_ventas (1000 filas) insertado\n",
            "Chunk 477 de rem_ventas (1000 filas) insertado\n",
            "Chunk 478 de rem_ventas (1000 filas) insertado\n",
            "Chunk 479 de rem_ventas (1000 filas) insertado\n",
            "Chunk 480 de rem_ventas (1000 filas) insertado\n",
            "Chunk 481 de rem_ventas (1000 filas) insertado\n",
            "Chunk 482 de rem_ventas (1000 filas) insertado\n",
            "Chunk 483 de rem_ventas (1000 filas) insertado\n",
            "Chunk 484 de rem_ventas (1000 filas) insertado\n",
            "Chunk 485 de rem_ventas (1000 filas) insertado\n",
            "Chunk 486 de rem_ventas (1000 filas) insertado\n",
            "Chunk 487 de rem_ventas (1000 filas) insertado\n",
            "Chunk 488 de rem_ventas (1000 filas) insertado\n",
            "Chunk 489 de rem_ventas (1000 filas) insertado\n",
            "Chunk 490 de rem_ventas (1000 filas) insertado\n",
            "Chunk 491 de rem_ventas (1000 filas) insertado\n",
            "Chunk 492 de rem_ventas (1000 filas) insertado\n",
            "Chunk 493 de rem_ventas (1000 filas) insertado\n",
            "Chunk 494 de rem_ventas (1000 filas) insertado\n",
            "Chunk 495 de rem_ventas (1000 filas) insertado\n",
            "Chunk 496 de rem_ventas (1000 filas) insertado\n",
            "Chunk 497 de rem_ventas (1000 filas) insertado\n",
            "Chunk 498 de rem_ventas (1000 filas) insertado\n",
            "Chunk 499 de rem_ventas (1000 filas) insertado\n",
            "Chunk 500 de rem_ventas (1000 filas) insertado\n",
            "Chunk 501 de rem_ventas (1000 filas) insertado\n",
            "Chunk 502 de rem_ventas (1000 filas) insertado\n",
            "Chunk 503 de rem_ventas (1000 filas) insertado\n",
            "Chunk 504 de rem_ventas (1000 filas) insertado\n",
            "Chunk 505 de rem_ventas (1000 filas) insertado\n",
            "Chunk 506 de rem_ventas (1000 filas) insertado\n",
            "Chunk 507 de rem_ventas (1000 filas) insertado\n",
            "Chunk 508 de rem_ventas (1000 filas) insertado\n",
            "Chunk 509 de rem_ventas (1000 filas) insertado\n",
            "Chunk 510 de rem_ventas (1000 filas) insertado\n",
            "Chunk 511 de rem_ventas (1000 filas) insertado\n",
            "Chunk 512 de rem_ventas (1000 filas) insertado\n",
            "Chunk 513 de rem_ventas (1000 filas) insertado\n",
            "Chunk 514 de rem_ventas (1000 filas) insertado\n",
            "Chunk 515 de rem_ventas (1000 filas) insertado\n",
            "Chunk 516 de rem_ventas (1000 filas) insertado\n",
            "Chunk 517 de rem_ventas (1000 filas) insertado\n",
            "Chunk 518 de rem_ventas (1000 filas) insertado\n",
            "Chunk 519 de rem_ventas (1000 filas) insertado\n",
            "Chunk 520 de rem_ventas (1000 filas) insertado\n",
            "Chunk 521 de rem_ventas (1000 filas) insertado\n",
            "Chunk 522 de rem_ventas (1000 filas) insertado\n",
            "Chunk 523 de rem_ventas (1000 filas) insertado\n",
            "Chunk 524 de rem_ventas (1000 filas) insertado\n",
            "Chunk 525 de rem_ventas (1000 filas) insertado\n",
            "Chunk 526 de rem_ventas (1000 filas) insertado\n",
            "Chunk 527 de rem_ventas (1000 filas) insertado\n",
            "Chunk 528 de rem_ventas (1000 filas) insertado\n",
            "Chunk 529 de rem_ventas (1000 filas) insertado\n",
            "Chunk 530 de rem_ventas (1000 filas) insertado\n",
            "Chunk 531 de rem_ventas (1000 filas) insertado\n",
            "Chunk 532 de rem_ventas (1000 filas) insertado\n",
            "Chunk 533 de rem_ventas (1000 filas) insertado\n",
            "Chunk 534 de rem_ventas (1000 filas) insertado\n",
            "Chunk 535 de rem_ventas (1000 filas) insertado\n",
            "Chunk 536 de rem_ventas (1000 filas) insertado\n",
            "Chunk 537 de rem_ventas (1000 filas) insertado\n",
            "Chunk 538 de rem_ventas (1000 filas) insertado\n",
            "Chunk 539 de rem_ventas (1000 filas) insertado\n",
            "Chunk 540 de rem_ventas (1000 filas) insertado\n",
            "Chunk 541 de rem_ventas (1000 filas) insertado\n",
            "Chunk 542 de rem_ventas (1000 filas) insertado\n",
            "Chunk 543 de rem_ventas (1000 filas) insertado\n",
            "Chunk 544 de rem_ventas (1000 filas) insertado\n",
            "Chunk 545 de rem_ventas (1000 filas) insertado\n",
            "Chunk 546 de rem_ventas (1000 filas) insertado\n",
            "Chunk 547 de rem_ventas (1000 filas) insertado\n",
            "Chunk 548 de rem_ventas (1000 filas) insertado\n",
            "Chunk 549 de rem_ventas (1000 filas) insertado\n",
            "Chunk 550 de rem_ventas (1000 filas) insertado\n",
            "Chunk 551 de rem_ventas (1000 filas) insertado\n",
            "Chunk 552 de rem_ventas (1000 filas) insertado\n",
            "Chunk 553 de rem_ventas (1000 filas) insertado\n",
            "Chunk 554 de rem_ventas (1000 filas) insertado\n",
            "Chunk 555 de rem_ventas (1000 filas) insertado\n",
            "Chunk 556 de rem_ventas (1000 filas) insertado\n",
            "Chunk 557 de rem_ventas (1000 filas) insertado\n",
            "Chunk 558 de rem_ventas (1000 filas) insertado\n",
            "Chunk 559 de rem_ventas (1000 filas) insertado\n",
            "Chunk 560 de rem_ventas (1000 filas) insertado\n",
            "Chunk 561 de rem_ventas (1000 filas) insertado\n",
            "Chunk 562 de rem_ventas (1000 filas) insertado\n",
            "Chunk 563 de rem_ventas (1000 filas) insertado\n",
            "Chunk 564 de rem_ventas (1000 filas) insertado\n",
            "Chunk 565 de rem_ventas (1000 filas) insertado\n",
            "Chunk 566 de rem_ventas (1000 filas) insertado\n",
            "Chunk 567 de rem_ventas (1000 filas) insertado\n",
            "Chunk 568 de rem_ventas (1000 filas) insertado\n",
            "Chunk 569 de rem_ventas (1000 filas) insertado\n",
            "Chunk 570 de rem_ventas (1000 filas) insertado\n",
            "Chunk 571 de rem_ventas (1000 filas) insertado\n",
            "Chunk 572 de rem_ventas (1000 filas) insertado\n",
            "Chunk 573 de rem_ventas (1000 filas) insertado\n",
            "Chunk 574 de rem_ventas (1000 filas) insertado\n",
            "Chunk 575 de rem_ventas (1000 filas) insertado\n",
            "Chunk 576 de rem_ventas (1000 filas) insertado\n",
            "Chunk 577 de rem_ventas (1000 filas) insertado\n",
            "Chunk 578 de rem_ventas (1000 filas) insertado\n",
            "Chunk 579 de rem_ventas (1000 filas) insertado\n",
            "Chunk 580 de rem_ventas (1000 filas) insertado\n",
            "Chunk 581 de rem_ventas (1000 filas) insertado\n",
            "Chunk 582 de rem_ventas (1000 filas) insertado\n",
            "Chunk 583 de rem_ventas (1000 filas) insertado\n",
            "Chunk 584 de rem_ventas (1000 filas) insertado\n",
            "Chunk 585 de rem_ventas (1000 filas) insertado\n",
            "Chunk 586 de rem_ventas (1000 filas) insertado\n",
            "Chunk 587 de rem_ventas (1000 filas) insertado\n",
            "Chunk 588 de rem_ventas (1000 filas) insertado\n",
            "Chunk 589 de rem_ventas (1000 filas) insertado\n",
            "Chunk 590 de rem_ventas (1000 filas) insertado\n",
            "Chunk 591 de rem_ventas (1000 filas) insertado\n",
            "Chunk 592 de rem_ventas (1000 filas) insertado\n",
            "Chunk 593 de rem_ventas (1000 filas) insertado\n",
            "Chunk 594 de rem_ventas (1000 filas) insertado\n",
            "Chunk 595 de rem_ventas (1000 filas) insertado\n",
            "Chunk 596 de rem_ventas (1000 filas) insertado\n",
            "Chunk 597 de rem_ventas (1000 filas) insertado\n",
            "Chunk 598 de rem_ventas (1000 filas) insertado\n",
            "Chunk 599 de rem_ventas (1000 filas) insertado\n",
            "Chunk 600 de rem_ventas (1000 filas) insertado\n",
            "Chunk 601 de rem_ventas (1000 filas) insertado\n",
            "Chunk 602 de rem_ventas (1000 filas) insertado\n",
            "Chunk 603 de rem_ventas (1000 filas) insertado\n",
            "Chunk 604 de rem_ventas (1000 filas) insertado\n",
            "Chunk 605 de rem_ventas (1000 filas) insertado\n",
            "Chunk 606 de rem_ventas (1000 filas) insertado\n",
            "Chunk 607 de rem_ventas (1000 filas) insertado\n",
            "Chunk 608 de rem_ventas (1000 filas) insertado\n",
            "Chunk 609 de rem_ventas (1000 filas) insertado\n",
            "Chunk 610 de rem_ventas (1000 filas) insertado\n",
            "Chunk 611 de rem_ventas (1000 filas) insertado\n",
            "Chunk 612 de rem_ventas (1000 filas) insertado\n",
            "Chunk 613 de rem_ventas (1000 filas) insertado\n",
            "Chunk 614 de rem_ventas (1000 filas) insertado\n",
            "Chunk 615 de rem_ventas (1000 filas) insertado\n",
            "Chunk 616 de rem_ventas (1000 filas) insertado\n",
            "Chunk 617 de rem_ventas (1000 filas) insertado\n",
            "Chunk 618 de rem_ventas (1000 filas) insertado\n",
            "Chunk 619 de rem_ventas (1000 filas) insertado\n",
            "Chunk 620 de rem_ventas (1000 filas) insertado\n",
            "Chunk 621 de rem_ventas (1000 filas) insertado\n",
            "Chunk 622 de rem_ventas (1000 filas) insertado\n",
            "Chunk 623 de rem_ventas (1000 filas) insertado\n",
            "Chunk 624 de rem_ventas (1000 filas) insertado\n",
            "Chunk 625 de rem_ventas (1000 filas) insertado\n",
            "Chunk 626 de rem_ventas (1000 filas) insertado\n",
            "Chunk 627 de rem_ventas (1000 filas) insertado\n",
            "Chunk 628 de rem_ventas (1000 filas) insertado\n",
            "Chunk 629 de rem_ventas (1000 filas) insertado\n",
            "Chunk 630 de rem_ventas (1000 filas) insertado\n",
            "Chunk 631 de rem_ventas (1000 filas) insertado\n",
            "Chunk 632 de rem_ventas (1000 filas) insertado\n",
            "Chunk 633 de rem_ventas (1000 filas) insertado\n",
            "Chunk 634 de rem_ventas (1000 filas) insertado\n",
            "Chunk 635 de rem_ventas (1000 filas) insertado\n",
            "Chunk 636 de rem_ventas (1000 filas) insertado\n",
            "Chunk 637 de rem_ventas (1000 filas) insertado\n",
            "Chunk 638 de rem_ventas (1000 filas) insertado\n",
            "Chunk 639 de rem_ventas (1000 filas) insertado\n",
            "Chunk 640 de rem_ventas (1000 filas) insertado\n",
            "Chunk 641 de rem_ventas (1000 filas) insertado\n",
            "Chunk 642 de rem_ventas (1000 filas) insertado\n",
            "Chunk 643 de rem_ventas (1000 filas) insertado\n",
            "Chunk 644 de rem_ventas (1000 filas) insertado\n",
            "Chunk 645 de rem_ventas (1000 filas) insertado\n",
            "Chunk 646 de rem_ventas (1000 filas) insertado\n",
            "Chunk 647 de rem_ventas (1000 filas) insertado\n",
            "Chunk 648 de rem_ventas (1000 filas) insertado\n",
            "Chunk 649 de rem_ventas (1000 filas) insertado\n",
            "Chunk 650 de rem_ventas (1000 filas) insertado\n",
            "Chunk 651 de rem_ventas (1000 filas) insertado\n",
            "Chunk 652 de rem_ventas (1000 filas) insertado\n",
            "Chunk 653 de rem_ventas (1000 filas) insertado\n",
            "Chunk 654 de rem_ventas (1000 filas) insertado\n",
            "Chunk 655 de rem_ventas (1000 filas) insertado\n",
            "Chunk 656 de rem_ventas (1000 filas) insertado\n",
            "Chunk 657 de rem_ventas (1000 filas) insertado\n",
            "Chunk 658 de rem_ventas (1000 filas) insertado\n",
            "Chunk 659 de rem_ventas (1000 filas) insertado\n",
            "Chunk 660 de rem_ventas (1000 filas) insertado\n",
            "Chunk 661 de rem_ventas (1000 filas) insertado\n",
            "Chunk 662 de rem_ventas (1000 filas) insertado\n",
            "Chunk 663 de rem_ventas (1000 filas) insertado\n",
            "Chunk 664 de rem_ventas (1000 filas) insertado\n",
            "Chunk 665 de rem_ventas (1000 filas) insertado\n",
            "Chunk 666 de rem_ventas (1000 filas) insertado\n",
            "Chunk 667 de rem_ventas (1000 filas) insertado\n",
            "Chunk 668 de rem_ventas (1000 filas) insertado\n",
            "Chunk 669 de rem_ventas (1000 filas) insertado\n",
            "Chunk 670 de rem_ventas (1000 filas) insertado\n",
            "Chunk 671 de rem_ventas (1000 filas) insertado\n",
            "Chunk 672 de rem_ventas (1000 filas) insertado\n",
            "Chunk 673 de rem_ventas (1000 filas) insertado\n",
            "Chunk 674 de rem_ventas (1000 filas) insertado\n",
            "Chunk 675 de rem_ventas (1000 filas) insertado\n",
            "Chunk 676 de rem_ventas (1000 filas) insertado\n",
            "Chunk 677 de rem_ventas (1000 filas) insertado\n",
            "Chunk 678 de rem_ventas (1000 filas) insertado\n",
            "Chunk 679 de rem_ventas (1000 filas) insertado\n",
            "Chunk 680 de rem_ventas (1000 filas) insertado\n",
            "Chunk 681 de rem_ventas (1000 filas) insertado\n",
            "Chunk 682 de rem_ventas (1000 filas) insertado\n",
            "Chunk 683 de rem_ventas (1000 filas) insertado\n",
            "Chunk 684 de rem_ventas (1000 filas) insertado\n",
            "Chunk 685 de rem_ventas (1000 filas) insertado\n",
            "Chunk 686 de rem_ventas (1000 filas) insertado\n",
            "Chunk 687 de rem_ventas (1000 filas) insertado\n",
            "Chunk 688 de rem_ventas (1000 filas) insertado\n",
            "Chunk 689 de rem_ventas (1000 filas) insertado\n",
            "Chunk 690 de rem_ventas (1000 filas) insertado\n",
            "Chunk 691 de rem_ventas (1000 filas) insertado\n",
            "Chunk 692 de rem_ventas (1000 filas) insertado\n",
            "Chunk 693 de rem_ventas (1000 filas) insertado\n",
            "Chunk 694 de rem_ventas (1000 filas) insertado\n",
            "Chunk 695 de rem_ventas (1000 filas) insertado\n",
            "Chunk 696 de rem_ventas (1000 filas) insertado\n",
            "Chunk 697 de rem_ventas (1000 filas) insertado\n",
            "Chunk 698 de rem_ventas (1000 filas) insertado\n",
            "Chunk 699 de rem_ventas (1000 filas) insertado\n",
            "Chunk 700 de rem_ventas (1000 filas) insertado\n",
            "Chunk 701 de rem_ventas (1000 filas) insertado\n",
            "Chunk 702 de rem_ventas (1000 filas) insertado\n",
            "Chunk 703 de rem_ventas (1000 filas) insertado\n",
            "Chunk 704 de rem_ventas (1000 filas) insertado\n",
            "Chunk 705 de rem_ventas (1000 filas) insertado\n",
            "Chunk 706 de rem_ventas (1000 filas) insertado\n",
            "Chunk 707 de rem_ventas (1000 filas) insertado\n",
            "Chunk 708 de rem_ventas (1000 filas) insertado\n",
            "Chunk 709 de rem_ventas (1000 filas) insertado\n",
            "Chunk 710 de rem_ventas (1000 filas) insertado\n",
            "Chunk 711 de rem_ventas (1000 filas) insertado\n",
            "Chunk 712 de rem_ventas (1000 filas) insertado\n",
            "Chunk 713 de rem_ventas (1000 filas) insertado\n",
            "Chunk 714 de rem_ventas (1000 filas) insertado\n",
            "Chunk 715 de rem_ventas (1000 filas) insertado\n",
            "Chunk 716 de rem_ventas (1000 filas) insertado\n",
            "Chunk 717 de rem_ventas (1000 filas) insertado\n",
            "Chunk 718 de rem_ventas (1000 filas) insertado\n",
            "Chunk 719 de rem_ventas (1000 filas) insertado\n",
            "Chunk 720 de rem_ventas (1000 filas) insertado\n",
            "Chunk 721 de rem_ventas (1000 filas) insertado\n",
            "Chunk 722 de rem_ventas (1000 filas) insertado\n",
            "Chunk 723 de rem_ventas (1000 filas) insertado\n",
            "Chunk 724 de rem_ventas (1000 filas) insertado\n",
            "Chunk 725 de rem_ventas (1000 filas) insertado\n",
            "Chunk 726 de rem_ventas (1000 filas) insertado\n",
            "Chunk 727 de rem_ventas (1000 filas) insertado\n",
            "Chunk 728 de rem_ventas (1000 filas) insertado\n",
            "Chunk 729 de rem_ventas (1000 filas) insertado\n",
            "Chunk 730 de rem_ventas (1000 filas) insertado\n",
            "Chunk 731 de rem_ventas (1000 filas) insertado\n",
            "Chunk 732 de rem_ventas (1000 filas) insertado\n",
            "Chunk 733 de rem_ventas (1000 filas) insertado\n",
            "Chunk 734 de rem_ventas (1000 filas) insertado\n",
            "Chunk 735 de rem_ventas (1000 filas) insertado\n",
            "Chunk 736 de rem_ventas (1000 filas) insertado\n",
            "Chunk 737 de rem_ventas (1000 filas) insertado\n",
            "Chunk 738 de rem_ventas (1000 filas) insertado\n",
            "Chunk 739 de rem_ventas (1000 filas) insertado\n",
            "Chunk 740 de rem_ventas (1000 filas) insertado\n",
            "Chunk 741 de rem_ventas (1000 filas) insertado\n",
            "Chunk 742 de rem_ventas (1000 filas) insertado\n",
            "Chunk 743 de rem_ventas (1000 filas) insertado\n",
            "Chunk 744 de rem_ventas (1000 filas) insertado\n",
            "Chunk 745 de rem_ventas (1000 filas) insertado\n",
            "Chunk 746 de rem_ventas (1000 filas) insertado\n",
            "Chunk 747 de rem_ventas (1000 filas) insertado\n",
            "Chunk 748 de rem_ventas (1000 filas) insertado\n",
            "Chunk 749 de rem_ventas (1000 filas) insertado\n",
            "Chunk 750 de rem_ventas (1000 filas) insertado\n",
            "Chunk 751 de rem_ventas (1000 filas) insertado\n",
            "Chunk 752 de rem_ventas (1000 filas) insertado\n",
            "Chunk 753 de rem_ventas (1000 filas) insertado\n",
            "Chunk 754 de rem_ventas (1000 filas) insertado\n",
            "Chunk 755 de rem_ventas (1000 filas) insertado\n",
            "Chunk 756 de rem_ventas (1000 filas) insertado\n",
            "Chunk 757 de rem_ventas (1000 filas) insertado\n",
            "Chunk 758 de rem_ventas (1000 filas) insertado\n",
            "Chunk 759 de rem_ventas (1000 filas) insertado\n",
            "Chunk 760 de rem_ventas (1000 filas) insertado\n",
            "Chunk 761 de rem_ventas (1000 filas) insertado\n",
            "Chunk 762 de rem_ventas (1000 filas) insertado\n",
            "Chunk 763 de rem_ventas (1000 filas) insertado\n",
            "Chunk 764 de rem_ventas (1000 filas) insertado\n",
            "Chunk 765 de rem_ventas (1000 filas) insertado\n",
            "Chunk 766 de rem_ventas (1000 filas) insertado\n",
            "Chunk 767 de rem_ventas (1000 filas) insertado\n",
            "Chunk 768 de rem_ventas (1000 filas) insertado\n",
            "Chunk 769 de rem_ventas (1000 filas) insertado\n",
            "Chunk 770 de rem_ventas (1000 filas) insertado\n",
            "Chunk 771 de rem_ventas (1000 filas) insertado\n",
            "Chunk 772 de rem_ventas (1000 filas) insertado\n",
            "Chunk 773 de rem_ventas (1000 filas) insertado\n",
            "Chunk 774 de rem_ventas (1000 filas) insertado\n",
            "Chunk 775 de rem_ventas (1000 filas) insertado\n",
            "Chunk 776 de rem_ventas (1000 filas) insertado\n",
            "Chunk 777 de rem_ventas (1000 filas) insertado\n",
            "Chunk 778 de rem_ventas (1000 filas) insertado\n",
            "Chunk 779 de rem_ventas (1000 filas) insertado\n",
            "Chunk 780 de rem_ventas (1000 filas) insertado\n",
            "Chunk 781 de rem_ventas (1000 filas) insertado\n",
            "Chunk 782 de rem_ventas (1000 filas) insertado\n",
            "Chunk 783 de rem_ventas (1000 filas) insertado\n",
            "Chunk 784 de rem_ventas (1000 filas) insertado\n",
            "Chunk 785 de rem_ventas (1000 filas) insertado\n",
            "Chunk 786 de rem_ventas (1000 filas) insertado\n",
            "Chunk 787 de rem_ventas (1000 filas) insertado\n",
            "Chunk 788 de rem_ventas (1000 filas) insertado\n",
            "Chunk 789 de rem_ventas (1000 filas) insertado\n",
            "Chunk 790 de rem_ventas (1000 filas) insertado\n",
            "Chunk 791 de rem_ventas (1000 filas) insertado\n",
            "Chunk 792 de rem_ventas (1000 filas) insertado\n",
            "Chunk 793 de rem_ventas (1000 filas) insertado\n",
            "Chunk 794 de rem_ventas (1000 filas) insertado\n",
            "Chunk 795 de rem_ventas (1000 filas) insertado\n",
            "Chunk 796 de rem_ventas (1000 filas) insertado\n",
            "Chunk 797 de rem_ventas (1000 filas) insertado\n",
            "Chunk 798 de rem_ventas (1000 filas) insertado\n",
            "Chunk 799 de rem_ventas (1000 filas) insertado\n",
            "Chunk 800 de rem_ventas (1000 filas) insertado\n",
            "Chunk 801 de rem_ventas (1000 filas) insertado\n",
            "Chunk 802 de rem_ventas (1000 filas) insertado\n",
            "Chunk 803 de rem_ventas (1000 filas) insertado\n",
            "Chunk 804 de rem_ventas (1000 filas) insertado\n",
            "Chunk 805 de rem_ventas (1000 filas) insertado\n",
            "Chunk 806 de rem_ventas (1000 filas) insertado\n",
            "Chunk 807 de rem_ventas (1000 filas) insertado\n",
            "Chunk 808 de rem_ventas (1000 filas) insertado\n",
            "Chunk 809 de rem_ventas (1000 filas) insertado\n",
            "Chunk 810 de rem_ventas (1000 filas) insertado\n",
            "Chunk 811 de rem_ventas (1000 filas) insertado\n",
            "Chunk 812 de rem_ventas (1000 filas) insertado\n",
            "Chunk 813 de rem_ventas (1000 filas) insertado\n",
            "Chunk 814 de rem_ventas (1000 filas) insertado\n",
            "Chunk 815 de rem_ventas (1000 filas) insertado\n",
            "Chunk 816 de rem_ventas (1000 filas) insertado\n",
            "Chunk 817 de rem_ventas (1000 filas) insertado\n",
            "Chunk 818 de rem_ventas (1000 filas) insertado\n",
            "Chunk 819 de rem_ventas (1000 filas) insertado\n",
            "Chunk 820 de rem_ventas (1000 filas) insertado\n",
            "Chunk 821 de rem_ventas (1000 filas) insertado\n",
            "Chunk 822 de rem_ventas (1000 filas) insertado\n",
            "Chunk 823 de rem_ventas (1000 filas) insertado\n",
            "Chunk 824 de rem_ventas (1000 filas) insertado\n",
            "Chunk 825 de rem_ventas (1000 filas) insertado\n",
            "Chunk 826 de rem_ventas (1000 filas) insertado\n",
            "Chunk 827 de rem_ventas (1000 filas) insertado\n",
            "Chunk 828 de rem_ventas (1000 filas) insertado\n",
            "Chunk 829 de rem_ventas (1000 filas) insertado\n",
            "Chunk 830 de rem_ventas (1000 filas) insertado\n",
            "Chunk 831 de rem_ventas (1000 filas) insertado\n",
            "Chunk 832 de rem_ventas (1000 filas) insertado\n",
            "Chunk 833 de rem_ventas (1000 filas) insertado\n",
            "Chunk 834 de rem_ventas (1000 filas) insertado\n",
            "Chunk 835 de rem_ventas (1000 filas) insertado\n",
            "Chunk 836 de rem_ventas (1000 filas) insertado\n",
            "Chunk 837 de rem_ventas (1000 filas) insertado\n",
            "Chunk 838 de rem_ventas (1000 filas) insertado\n",
            "Chunk 839 de rem_ventas (1000 filas) insertado\n",
            "Chunk 840 de rem_ventas (1000 filas) insertado\n",
            "Chunk 841 de rem_ventas (1000 filas) insertado\n",
            "Chunk 842 de rem_ventas (1000 filas) insertado\n",
            "Chunk 843 de rem_ventas (1000 filas) insertado\n",
            "Chunk 844 de rem_ventas (1000 filas) insertado\n",
            "Chunk 845 de rem_ventas (1000 filas) insertado\n",
            "Chunk 846 de rem_ventas (1000 filas) insertado\n",
            "Chunk 847 de rem_ventas (1000 filas) insertado\n",
            "Chunk 848 de rem_ventas (1000 filas) insertado\n",
            "Chunk 849 de rem_ventas (1000 filas) insertado\n",
            "Chunk 850 de rem_ventas (1000 filas) insertado\n",
            "Chunk 851 de rem_ventas (1000 filas) insertado\n",
            "Chunk 852 de rem_ventas (1000 filas) insertado\n",
            "Chunk 853 de rem_ventas (1000 filas) insertado\n",
            "Chunk 854 de rem_ventas (1000 filas) insertado\n",
            "Chunk 855 de rem_ventas (1000 filas) insertado\n",
            "Chunk 856 de rem_ventas (1000 filas) insertado\n",
            "Chunk 857 de rem_ventas (1000 filas) insertado\n",
            "Chunk 858 de rem_ventas (1000 filas) insertado\n",
            "Chunk 859 de rem_ventas (1000 filas) insertado\n",
            "Chunk 860 de rem_ventas (1000 filas) insertado\n",
            "Chunk 861 de rem_ventas (1000 filas) insertado\n",
            "Chunk 862 de rem_ventas (1000 filas) insertado\n",
            "Chunk 863 de rem_ventas (1000 filas) insertado\n",
            "Chunk 864 de rem_ventas (1000 filas) insertado\n",
            "Chunk 865 de rem_ventas (1000 filas) insertado\n",
            "Chunk 866 de rem_ventas (1000 filas) insertado\n",
            "Chunk 867 de rem_ventas (1000 filas) insertado\n",
            "Chunk 868 de rem_ventas (1000 filas) insertado\n",
            "Chunk 869 de rem_ventas (1000 filas) insertado\n",
            "Chunk 870 de rem_ventas (1000 filas) insertado\n",
            "Chunk 871 de rem_ventas (1000 filas) insertado\n",
            "Chunk 872 de rem_ventas (1000 filas) insertado\n",
            "Chunk 873 de rem_ventas (1000 filas) insertado\n",
            "Chunk 874 de rem_ventas (1000 filas) insertado\n",
            "Chunk 875 de rem_ventas (1000 filas) insertado\n",
            "Chunk 876 de rem_ventas (1000 filas) insertado\n",
            "Chunk 877 de rem_ventas (1000 filas) insertado\n",
            "Chunk 878 de rem_ventas (1000 filas) insertado\n",
            "Chunk 879 de rem_ventas (1000 filas) insertado\n",
            "Chunk 880 de rem_ventas (1000 filas) insertado\n",
            "Chunk 881 de rem_ventas (1000 filas) insertado\n",
            "Chunk 882 de rem_ventas (1000 filas) insertado\n",
            "Chunk 883 de rem_ventas (1000 filas) insertado\n",
            "Chunk 884 de rem_ventas (1000 filas) insertado\n",
            "Chunk 885 de rem_ventas (1000 filas) insertado\n",
            "Chunk 886 de rem_ventas (1000 filas) insertado\n",
            "Chunk 887 de rem_ventas (1000 filas) insertado\n",
            "Chunk 888 de rem_ventas (1000 filas) insertado\n",
            "Chunk 889 de rem_ventas (1000 filas) insertado\n",
            "Chunk 890 de rem_ventas (1000 filas) insertado\n",
            "Chunk 891 de rem_ventas (1000 filas) insertado\n",
            "Chunk 892 de rem_ventas (1000 filas) insertado\n",
            "Chunk 893 de rem_ventas (1000 filas) insertado\n",
            "Chunk 894 de rem_ventas (1000 filas) insertado\n",
            "Chunk 895 de rem_ventas (1000 filas) insertado\n",
            "Chunk 896 de rem_ventas (1000 filas) insertado\n",
            "Chunk 897 de rem_ventas (1000 filas) insertado\n",
            "Chunk 898 de rem_ventas (1000 filas) insertado\n",
            "Chunk 899 de rem_ventas (1000 filas) insertado\n",
            "Chunk 900 de rem_ventas (1000 filas) insertado\n",
            "Chunk 901 de rem_ventas (1000 filas) insertado\n",
            "Chunk 902 de rem_ventas (1000 filas) insertado\n",
            "Chunk 903 de rem_ventas (1000 filas) insertado\n",
            "Chunk 904 de rem_ventas (1000 filas) insertado\n",
            "Chunk 905 de rem_ventas (1000 filas) insertado\n",
            "Chunk 906 de rem_ventas (1000 filas) insertado\n",
            "Chunk 907 de rem_ventas (1000 filas) insertado\n",
            "Chunk 908 de rem_ventas (1000 filas) insertado\n",
            "Chunk 909 de rem_ventas (1000 filas) insertado\n",
            "Chunk 910 de rem_ventas (1000 filas) insertado\n",
            "Chunk 911 de rem_ventas (1000 filas) insertado\n",
            "Chunk 912 de rem_ventas (1000 filas) insertado\n",
            "Chunk 913 de rem_ventas (1000 filas) insertado\n",
            "Chunk 914 de rem_ventas (1000 filas) insertado\n",
            "Chunk 915 de rem_ventas (1000 filas) insertado\n",
            "Chunk 916 de rem_ventas (1000 filas) insertado\n",
            "Chunk 917 de rem_ventas (1000 filas) insertado\n",
            "Chunk 918 de rem_ventas (1000 filas) insertado\n",
            "Chunk 919 de rem_ventas (1000 filas) insertado\n",
            "Chunk 920 de rem_ventas (1000 filas) insertado\n",
            "Chunk 921 de rem_ventas (1000 filas) insertado\n",
            "Chunk 922 de rem_ventas (1000 filas) insertado\n",
            "Chunk 923 de rem_ventas (1000 filas) insertado\n",
            "Chunk 924 de rem_ventas (1000 filas) insertado\n",
            "Chunk 925 de rem_ventas (1000 filas) insertado\n",
            "Chunk 926 de rem_ventas (1000 filas) insertado\n",
            "Chunk 927 de rem_ventas (1000 filas) insertado\n",
            "Chunk 928 de rem_ventas (1000 filas) insertado\n",
            "Chunk 929 de rem_ventas (1000 filas) insertado\n",
            "Chunk 930 de rem_ventas (1000 filas) insertado\n",
            "Chunk 931 de rem_ventas (1000 filas) insertado\n",
            "Chunk 932 de rem_ventas (1000 filas) insertado\n",
            "Chunk 933 de rem_ventas (1000 filas) insertado\n",
            "Chunk 934 de rem_ventas (1000 filas) insertado\n",
            "Chunk 935 de rem_ventas (1000 filas) insertado\n",
            "Chunk 936 de rem_ventas (1000 filas) insertado\n",
            "Chunk 937 de rem_ventas (1000 filas) insertado\n",
            "Chunk 938 de rem_ventas (1000 filas) insertado\n",
            "Chunk 939 de rem_ventas (1000 filas) insertado\n",
            "Chunk 940 de rem_ventas (1000 filas) insertado\n",
            "Chunk 941 de rem_ventas (425 filas) insertado\n",
            "Chunk 1 de rem_calendario (218 filas) insertado\n",
            "Chunk 1 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 2 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 3 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 4 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 5 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 6 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 7 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 8 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 9 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 10 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 11 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 12 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 13 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 14 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 15 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 16 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 17 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 18 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 19 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 20 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 21 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 22 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 23 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 24 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 25 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 26 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 27 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 28 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 29 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 30 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 31 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 32 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 33 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 34 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 35 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 36 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 37 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 38 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 39 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 40 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 41 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 42 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 43 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 44 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 45 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 46 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 47 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 48 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 49 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 50 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 51 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 52 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 53 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 54 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 55 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 56 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 57 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 58 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 59 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 60 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 61 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 62 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 63 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 64 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 65 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 66 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 67 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 68 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 69 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 70 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 71 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 72 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 73 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 74 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 75 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 76 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 77 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 78 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 79 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 80 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 81 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 82 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 83 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 84 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 85 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 86 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 87 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 88 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 89 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 90 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 91 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 92 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 93 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 94 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 95 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 96 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 97 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 98 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 99 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 100 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 101 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 102 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 103 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 104 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 105 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 106 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 107 de rem_pedidos (1000 filas) insertado\n",
            "Chunk 108 de rem_pedidos (905 filas) insertado\n",
            "Inserciones completadas.\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import insert, text\n",
        "\n",
        "CHUNK_SIZE = 1000\n",
        "\n",
        "# Función para insertar \"partes\" más livianas, si no me daba error\n",
        "def insertar_chunks(conn, tabla, df_pl: pl.DataFrame, nombre_tabla: str, chunk_size=CHUNK_SIZE):\n",
        "    registros = df_pl.to_dicts()\n",
        "    total = len(registros)\n",
        "    for i in range(0, total, chunk_size):\n",
        "        lote = registros[i:i+chunk_size]\n",
        "        conn.execute(insert(tabla), lote)\n",
        "        print(f\"Chunk {i//chunk_size+1} de {nombre_tabla} ({len(lote)} filas) insertado\")\n",
        "\n",
        "# Evita duplicados: vacía y carga UNA vez\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"TRUNCATE TABLE sandbox.rem_ventas;\"))\n",
        "    con.execute(text(\"TRUNCATE TABLE sandbox.rem_calendario;\"))\n",
        "    con.execute(text(\"TRUNCATE TABLE sandbox.rem_pedidos;\"))\n",
        "\n",
        "# Solo filas únicas en ventas (por si el Excel trae duplicados reales)\n",
        "subset_cols = [\"FAMILIA\",\"Tipo\",\"FechaVenta\",\"HoraVenta\",\"Articulo\",\"Cantidad\",\"Precio\",\"Importe\"]\n",
        "df_ventas_unique = df_ventas.unique(subset=subset_cols, keep=\"first\")\n",
        "\n",
        "with engine.begin() as con:\n",
        "    insertar_chunks(con, rem_ventas, df_ventas_unique, \"rem_ventas\")\n",
        "    insertar_chunks(con, rem_calendario, df_calendario, \"rem_calendario\")\n",
        "    insertar_chunks(con, rem_pedidos, df_pedidos, \"rem_pedidos\")\n",
        "\n",
        "print(\"Inserciones completadas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inserción eficiente de datos: aprendiendo y experimentando\n",
        "\n",
        "En este  proyecto, he probado distintas formas de cargar grandes volúmenes de datos (como la tabla de ventas) en MySQL.  \n",
        "Finalmente, me he decantado por la inserción en lotes (*chunks*) usando Polars y SQLAlchemy, por varias razones:\n",
        "\n",
        "- **Simplicidad y limpieza**: El código es mucho más corto y claro, sin necesidad de recorrer filas una a una ni construir registros manualmente.\n",
        "- **Rendimiento**: La inserción por lotes evita errores de conexión y permite que la carga sea sorprendentemente rápida (la tabla ventas, que es la mayor, se ha cargado en solo 1 minuto y 40 segundos).\n",
        "- **Aprendizaje**: Creo que he conseguido mejorar el rendimiento al notebook original, trabajando de forma más eficiente con grandes conjuntos de datos y bases SQL en Python, experimentando con distintos tamaños de lote (*chunk size* o muestras más pequeñas).\n",
        "\n",
        "En resumen, experimentar con Polars y SQLAlchemy, junto con la inserción en *chunks*, me ha permitido cargar los datos de manera profesional, rápida y con un código más fácil de mantener.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nota: las consultas siguientes están preparadas para lanzarse con los datos cargados en la bbdd data y con los nombres iniciales, si se lanzan con usuario1 debe adaptarse\n",
        "\n",
        "#### Voy a intentar hacer las consultas con SQLAlchemy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calendario_completo -> filas: 2556 | fechas únicas: 2556\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "START_DATE = \"2017-01-01\"\n",
        "END_DATE   = \"2023-12-31\"\n",
        "\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"SET SESSION cte_max_recursion_depth = 5000;\"))\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.calendario_dias;\"))\n",
        "    con.execute(text(f\"\"\"\n",
        "        CREATE TABLE sandbox.calendario_dias AS\n",
        "        WITH RECURSIVE cte_cal AS (\n",
        "            SELECT DATE('{START_DATE}') AS d\n",
        "            UNION ALL\n",
        "            SELECT DATE_ADD(d, INTERVAL 1 DAY)\n",
        "            FROM cte_cal\n",
        "            WHERE d < DATE('{END_DATE}')\n",
        "        )\n",
        "        SELECT\n",
        "            d                                        AS fecha,\n",
        "            YEAR(d)                                  AS fx_anno,\n",
        "            MONTH(d)                                 AS fx_mes,\n",
        "            DAY(d)                                   AS fx_day,\n",
        "            DATE_FORMAT(d, '%Y%m')                   AS fx_anno_mes,\n",
        "            DATE_FORMAT(d, '%x-%v')                  AS semana\n",
        "        FROM cte_cal;\n",
        "    \"\"\"))\n",
        "\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.rem_calendario_uniq;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.rem_calendario_uniq AS\n",
        "        SELECT \n",
        "            CAST(Fecha AS DATE) AS fecha,\n",
        "            MAX(Festivo)        AS festivo\n",
        "        FROM sandbox.rem_calendario\n",
        "        GROUP BY CAST(Fecha AS DATE);\n",
        "    \"\"\"))\n",
        "\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.calendario_completo;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.calendario_completo AS\n",
        "        SELECT\n",
        "            b.fecha, b.fx_anno, b.fx_mes, b.fx_day, b.fx_anno_mes, b.semana,\n",
        "            u.festivo\n",
        "        FROM sandbox.calendario_dias b\n",
        "        LEFT JOIN sandbox.rem_calendario_uniq u\n",
        "          ON b.fecha = u.fecha;\n",
        "    \"\"\"))\n",
        "\n",
        "    try:\n",
        "        con.execute(text(\"ALTER TABLE sandbox.calendario_completo ADD UNIQUE KEY uq_calendario_fecha (fecha);\"))\n",
        "    except Exception as e:\n",
        "        print(\"Aviso índice único:\", e)\n",
        "\n",
        "# Comprobación de unicidad\n",
        "with engine.connect() as con:\n",
        "    filas, fechas = con.execute(text(\"\"\"\n",
        "        SELECT COUNT(*) AS filas, COUNT(DISTINCT fecha) AS fechas FROM sandbox.calendario_completo;\n",
        "    \"\"\")).fetchone()\n",
        "    print(\"calendario_completo -> filas:\", filas, \"| fechas únicas:\", fechas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "articulos_top listo.\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.articulos_top;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.articulos_top AS\n",
        "        SELECT\n",
        "            t.Articulo,\n",
        "            t.FAMILIA,\n",
        "            t.importe_total,\n",
        "            ROW_NUMBER() OVER (PARTITION BY t.FAMILIA ORDER BY t.importe_total DESC) AS orden\n",
        "        FROM (\n",
        "            SELECT Articulo, FAMILIA, SUM(Importe) AS importe_total\n",
        "            FROM sandbox.rem_ventas\n",
        "            WHERE FechaVenta >= '2021-05-01' AND Tipo='VENTA'\n",
        "            GROUP BY 1,2\n",
        "        ) t;\n",
        "    \"\"\"))\n",
        "print(\"articulos_top listo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ventas_diarias reconstruida (solo cantidades > 0)\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    # Base agregada diaria SOLO VENTA y SOLO cantidades > 0\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.tmp_ventas_agg;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.tmp_ventas_agg AS\n",
        "        SELECT\n",
        "            DATE(FechaVenta) AS fecha,\n",
        "            Articulo,\n",
        "            MAX(FAMILIA)     AS familia,\n",
        "            'VENTA'          AS tipo,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cantidad,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Importe  ELSE 0 END) AS importe,\n",
        "            CASE\n",
        "              WHEN SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) = 0 THEN NULL\n",
        "              ELSE SUM(CASE WHEN Cantidad > 0 THEN Precio*Cantidad ELSE 0 END)\n",
        "                   / SUM(CASE WHEN Cantidad > 0 THEN Cantidad         ELSE 0 END)\n",
        "            END AS precio\n",
        "        FROM sandbox.rem_ventas\n",
        "        WHERE Tipo='VENTA'\n",
        "        GROUP BY 1,2;\n",
        "    \"\"\"))\n",
        "\n",
        "    # Final con calendario + ranking (1:1)\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.ventas_diarias;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.ventas_diarias AS\n",
        "        SELECT\n",
        "            v.familia, v.tipo, v.fecha, c.festivo,\n",
        "            v.Articulo, v.precio,\n",
        "            a.orden AS orden_articulo_familia,\n",
        "            CASE WHEN v.fecha >= DATE('2021-05-01') THEN 'S' ELSE 'N' END AS in_fecha_estudio,\n",
        "            v.cantidad, v.importe\n",
        "        FROM sandbox.tmp_ventas_agg v\n",
        "        LEFT JOIN sandbox.calendario_completo c ON v.fecha = c.fecha\n",
        "        LEFT JOIN sandbox.articulos_top a ON v.familia = a.FAMILIA AND v.Articulo = a.Articulo;\n",
        "    \"\"\"))\n",
        "\n",
        "    try:\n",
        "        con.execute(text(\"ALTER TABLE sandbox.ventas_diarias ADD UNIQUE KEY uq_ventas_dia_art (fecha, articulo);\"))\n",
        "    except Exception as e:\n",
        "        print(\"Aviso índice único:\", e)\n",
        "\n",
        "print(\"✅ ventas_diarias reconstruida (solo cantidades > 0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoke tests OK ✅\n"
          ]
        }
      ],
      "source": [
        "# Comprobaciones, es la tercera vez que rehago el proyecto por errores en la carga de datos\n",
        "# Ventas muy altas, precios, importes, etc.\n",
        "\n",
        "from sqlalchemy import text\n",
        "\n",
        "with engine.connect() as con:\n",
        "    # Coincidencia exacta con base (>0) por (fecha, articulo)\n",
        "    diff = con.execute(text(\"\"\"\n",
        "        WITH base AS (\n",
        "          SELECT DATE(FechaVenta) AS fecha, Articulo,\n",
        "                 SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cant_base\n",
        "          FROM sandbox.rem_ventas\n",
        "          WHERE Tipo='VENTA'\n",
        "          GROUP BY 1,2\n",
        "        ), comp AS (\n",
        "          SELECT v.fecha, v.articulo, v.cantidad - b.cant_base AS d\n",
        "          FROM sandbox.ventas_diarias v\n",
        "          JOIN base b ON v.fecha=b.fecha AND v.articulo=b.articulo\n",
        "        )\n",
        "        SELECT SUM(d<>0) FROM comp;\n",
        "    \"\"\")).scalar() or 0\n",
        "    assert diff == 0, f\"Diferencias base(>0) vs ventas_diarias: {diff}\"\n",
        "\n",
        "    # No negativos\n",
        "    negs = con.execute(text(\"SELECT SUM(cantidad<0) FROM sandbox.ventas_diarias\")).scalar() or 0\n",
        "    assert negs == 0, \"Cantidades negativas en ventas_diarias\"\n",
        "\n",
        "print(\"Smoke tests OK ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ventas_diarias creada/actualizada (VENTA y >0)\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    # Base agregada diaria SOLO VENTA y SOLO cantidades > 0\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.tmp_ventas_agg;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.tmp_ventas_agg AS\n",
        "        SELECT\n",
        "            DATE(FechaVenta) AS fecha,\n",
        "            Articulo,\n",
        "            MAX(FAMILIA)     AS familia,\n",
        "            'VENTA'          AS tipo,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cantidad,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Importe  ELSE 0 END) AS importe,\n",
        "            CASE\n",
        "              WHEN SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) = 0 THEN NULL\n",
        "              ELSE SUM(CASE WHEN Cantidad > 0 THEN Precio*Cantidad ELSE 0 END)\n",
        "                   / SUM(CASE WHEN Cantidad > 0 THEN Cantidad         ELSE 0 END)\n",
        "            END AS precio\n",
        "        FROM sandbox.rem_ventas\n",
        "        WHERE Tipo='VENTA'\n",
        "        GROUP BY 1,2;\n",
        "    \"\"\"))\n",
        "\n",
        "    # Final con calendario + ranking (1:1)\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.ventas_diarias;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.ventas_diarias AS\n",
        "        SELECT\n",
        "            v.familia, v.tipo, v.fecha, c.festivo,\n",
        "            v.Articulo, v.precio,\n",
        "            a.orden AS orden_articulo_familia,\n",
        "            CASE WHEN v.fecha >= DATE('2021-05-01') THEN 'S' ELSE 'N' END AS in_fecha_estudio,\n",
        "            v.cantidad, v.importe\n",
        "        FROM sandbox.tmp_ventas_agg v\n",
        "        LEFT JOIN sandbox.calendario_completo c ON v.fecha = c.fecha\n",
        "        LEFT JOIN sandbox.articulos_top a ON v.familia = a.FAMILIA AND v.Articulo = a.Articulo;\n",
        "    \"\"\"))\n",
        "\n",
        "    # Unicidad por (fecha, articulo)\n",
        "    try:\n",
        "        con.execute(text(\"ALTER TABLE sandbox.ventas_diarias ADD UNIQUE KEY uq_ventas_dia_art (fecha, articulo);\"))\n",
        "    except Exception as e:\n",
        "        print(\"Aviso (índice único):\", e)\n",
        "\n",
        "print(\"✅ ventas_diarias creada/actualizada (VENTA y >0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1,)\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "with engine.connect() as con:\n",
        "    print(con.execute(text(\"SELECT 1;\")).fetchone())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "articulos_top listo (VENTA).\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.articulos_top;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.articulos_top AS\n",
        "        SELECT\n",
        "            t.Articulo,\n",
        "            t.FAMILIA,\n",
        "            t.importe_total,\n",
        "            ROW_NUMBER() OVER (PARTITION BY t.FAMILIA ORDER BY t.importe_total DESC) AS orden\n",
        "        FROM (\n",
        "            SELECT Articulo, FAMILIA, SUM(Importe) AS importe_total\n",
        "            FROM sandbox.rem_ventas\n",
        "            WHERE FechaVenta >= '2021-05-01' AND Tipo='VENTA'\n",
        "            GROUP BY 1,2\n",
        "        ) t;\n",
        "    \"\"\"))\n",
        "print(\"articulos_top listo (VENTA).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ventas_diarias creada/actualizada (VENTA y >0).\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    # Base agregada diaria SOLO VENTA y SOLO cantidades > 0\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.tmp_ventas_agg;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.tmp_ventas_agg AS\n",
        "        SELECT\n",
        "            DATE(FechaVenta) AS fecha,\n",
        "            Articulo,\n",
        "            MAX(FAMILIA)     AS familia,\n",
        "            'VENTA'          AS tipo,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cantidad,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Importe  ELSE 0 END) AS importe,\n",
        "            CASE\n",
        "              WHEN SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) = 0 THEN NULL\n",
        "              ELSE SUM(CASE WHEN Cantidad > 0 THEN Precio*Cantidad ELSE 0 END)\n",
        "                   / SUM(CASE WHEN Cantidad > 0 THEN Cantidad         ELSE 0 END)\n",
        "            END AS precio\n",
        "        FROM sandbox.rem_ventas\n",
        "        WHERE Tipo='VENTA'\n",
        "        GROUP BY 1,2;\n",
        "    \"\"\"))\n",
        "\n",
        "    # Final con calendario + ranking (1:1)\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.ventas_diarias;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.ventas_diarias AS\n",
        "        SELECT\n",
        "            v.familia, v.tipo, v.fecha, c.festivo,\n",
        "            v.Articulo, v.precio,\n",
        "            a.orden AS orden_articulo_familia,\n",
        "            CASE WHEN v.fecha >= DATE('2021-05-01') THEN 'S' ELSE 'N' END AS in_fecha_estudio,\n",
        "            v.cantidad, v.importe\n",
        "        FROM sandbox.tmp_ventas_agg v\n",
        "        LEFT JOIN sandbox.calendario_completo c ON v.fecha = c.fecha\n",
        "        LEFT JOIN sandbox.articulos_top a ON v.familia = a.FAMILIA AND v.Articulo = a.Articulo;\n",
        "    \"\"\"))\n",
        "\n",
        "    # Unicidad por (fecha, articulo) (si existe, ignora aviso)\n",
        "    try:\n",
        "        con.execute(text(\"ALTER TABLE sandbox.ventas_diarias ADD UNIQUE KEY uq_ventas_dia_art (fecha, articulo);\"))\n",
        "    except Exception as e:\n",
        "        print(\"Aviso índice único:\", e)\n",
        "\n",
        "print(\"ventas_diarias creada/actualizada (VENTA y >0).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smoke tests OK ✅\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.connect() as con:\n",
        "    # Coincidencia exacta con base (VENTA y >0) por (fecha, articulo)\n",
        "    diff = con.execute(text(\"\"\"\n",
        "        WITH base AS (\n",
        "          SELECT DATE(FechaVenta) AS fecha, Articulo,\n",
        "                 SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cant_base\n",
        "          FROM sandbox.rem_ventas\n",
        "          WHERE Tipo='VENTA'\n",
        "          GROUP BY 1,2\n",
        "        ), comp AS (\n",
        "          SELECT v.fecha, v.articulo, v.cantidad - b.cant_base AS d\n",
        "          FROM sandbox.ventas_diarias v\n",
        "          JOIN base b ON v.fecha=b.fecha AND v.articulo=b.articulo\n",
        "        )\n",
        "        SELECT SUM(d<>0) FROM comp;\n",
        "    \"\"\")).scalar() or 0\n",
        "    assert diff == 0, f\"Diferencias base(>0) vs ventas_diarias: {diff}\"\n",
        "\n",
        "    # Unicidad y no-negativos\n",
        "    dups = con.execute(text(\"\"\"\n",
        "        SELECT COUNT(*) - COUNT(DISTINCT CONCAT_WS('|',fecha,articulo))\n",
        "        FROM sandbox.ventas_diarias\n",
        "    \"\"\")).scalar() or 0\n",
        "    assert dups == 0, f\"Duplicados en ventas_diarias: {dups}\"\n",
        "\n",
        "    negs = con.execute(text(\"SELECT SUM(cantidad<0) FROM sandbox.ventas_diarias\")).scalar() or 0\n",
        "    assert negs == 0, \"Cantidades negativas en ventas_diarias\"\n",
        "\n",
        "print(\"Smoke tests OK ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "with engine.begin() as con:\n",
        "    # 2.1) Rehacer ranking de artículos con solo VENTA\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.articulos_top;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.articulos_top AS\n",
        "        SELECT\n",
        "            t.Articulo,\n",
        "            t.FAMILIA,\n",
        "            t.importe_total,\n",
        "            ROW_NUMBER() OVER (PARTITION BY t.FAMILIA ORDER BY t.importe_total DESC) AS orden\n",
        "        FROM (\n",
        "            SELECT Articulo, FAMILIA, SUM(Importe) AS importe_total\n",
        "            FROM sandbox.rem_ventas\n",
        "            WHERE FechaVenta >= '2021-05-01' AND Tipo='VENTA'\n",
        "            GROUP BY 1,2\n",
        "        ) t;\n",
        "    \"\"\"))\n",
        "\n",
        "    # 2.2) Agregación diaria por artículo SOLO VENTA y SOLO cantidades > 0\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.tmp_ventas_agg;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.tmp_ventas_agg AS\n",
        "        SELECT\n",
        "            DATE(FechaVenta) AS fecha,\n",
        "            Articulo,\n",
        "            MAX(FAMILIA)     AS familia,\n",
        "            'VENTA'          AS tipo,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cantidad,\n",
        "            SUM(CASE WHEN Cantidad > 0 THEN Importe  ELSE 0 END) AS importe,\n",
        "            CASE\n",
        "              WHEN SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) = 0 THEN NULL\n",
        "              ELSE SUM(CASE WHEN Cantidad > 0 THEN Precio*Cantidad ELSE 0 END)\n",
        "                   / SUM(CASE WHEN Cantidad > 0 THEN Cantidad         ELSE 0 END)\n",
        "            END AS precio\n",
        "        FROM sandbox.rem_ventas\n",
        "        WHERE Tipo='VENTA'\n",
        "        GROUP BY 1,2;\n",
        "    \"\"\"))\n",
        "\n",
        "    # 2.3) ventas_diarias (join 1:1 con calendario y ranking)\n",
        "    con.execute(text(\"DROP TABLE IF EXISTS sandbox.ventas_diarias;\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE TABLE sandbox.ventas_diarias AS\n",
        "        SELECT\n",
        "            v.familia,\n",
        "            v.tipo,\n",
        "            v.fecha,\n",
        "            c.festivo,\n",
        "            v.Articulo,\n",
        "            v.precio,\n",
        "            a.orden AS orden_articulo_familia,\n",
        "            CASE WHEN v.fecha >= DATE('2021-05-01') THEN 'S' ELSE 'N' END AS in_fecha_estudio,\n",
        "            v.cantidad,\n",
        "            v.importe\n",
        "        FROM sandbox.tmp_ventas_agg v\n",
        "        LEFT JOIN sandbox.calendario_completo c\n",
        "          ON v.fecha = c.fecha\n",
        "        LEFT JOIN sandbox.articulos_top a\n",
        "          ON v.familia = a.FAMILIA AND v.Articulo = a.Articulo;\n",
        "    \"\"\"))\n",
        "\n",
        "    # 2.4) Blindaje (no crítico si falla)\n",
        "    try:\n",
        "        con.execute(text(\"\"\"\n",
        "            ALTER TABLE sandbox.ventas_diarias\n",
        "            ADD UNIQUE KEY uq_ventas_dia_art (fecha, articulo);\n",
        "        \"\"\"))\n",
        "    except Exception as e:\n",
        "        print(\"Aviso índice único (no crítico):\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vistas creadas/actualizadas ✅\n"
          ]
        }
      ],
      "source": [
        "# CREATE\n",
        "with engine.begin() as con:\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE OR REPLACE VIEW sandbox.ventas_diarias_estudio_completo AS\n",
        "        SELECT *\n",
        "        FROM sandbox.ventas_diarias\n",
        "        WHERE tipo='VENTA'\n",
        "          AND in_fecha_estudio='S'\n",
        "          AND orden_articulo_familia<=5;\n",
        "    \"\"\"))\n",
        "    con.execute(text(\"\"\"\n",
        "        CREATE OR REPLACE VIEW sandbox.ventas_diarias_estudio AS\n",
        "        SELECT *\n",
        "        FROM sandbox.ventas_diarias\n",
        "        WHERE tipo='VENTA'\n",
        "          AND in_fecha_estudio='S'\n",
        "          AND fecha < DATE('2023-05-01')\n",
        "          AND orden_articulo_familia<=5;\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"Vistas creadas/actualizadas ✅\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Recuento de filas ==\n",
            "✔ sandbox.articulos_top: 170 filas\n",
            "✔ sandbox.calendario_dias: 2556 filas\n",
            "✔ sandbox.calendario_completo: 2556 filas\n",
            "✔ sandbox.ventas_diarias: 140021 filas\n",
            "\n",
            "== Esquema ventas_diarias ==\n",
            "['familia', 'tipo', 'fecha', 'festivo', 'Articulo', 'precio', 'orden_articulo_familia', 'in_fecha_estudio', 'cantidad', 'importe']\n",
            "\n",
            "== Resumen ventas_diarias ==\n",
            "{'min_fecha': datetime.date(2017, 1, 1), 'max_fecha': datetime.date(2023, 5, 18), 'filas': 140021, 'n_articulos': 172, 'total_cantidad': 10366859.982097466}\n",
            "\n",
            "== Smoke tests ==\n",
            "✔ Consistencia con base (VENTA>0)\n",
            "✔ Unicidad (fecha, articulo)\n",
            "✔ Sin negativos\n",
            "\n",
            "== Primeras filas de vistas ==\n",
            "\n",
            "sandbox.ventas_diarias_estudio_completo:\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '1043', 2.5959999561309814, 2, 'S', 327.0, 848.8920021057129)\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '1084', 0.8650000095367432, 4, 'S', 423.0, 365.89500522613525)\n",
            "('BOLLERIA', 'VENTA', datetime.date(2021, 5, 1), None, '3880', 2.5910000801086426, 3, 'S', 285.0, 738.4349975585938)\n",
            "('BOLLERIA', 'VENTA', datetime.date(2021, 5, 1), None, '3960', 2.318000078201294, 1, 'S', 402.0, 931.835994720459)\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '417', 4.038000106811523, 5, 'S', 72.0, 290.7360038757324)\n",
            "\n",
            "sandbox.ventas_diarias_estudio:\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '1043', 2.5959999561309814, 2, 'S', 327.0, 848.8920021057129)\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '1084', 0.8650000095367432, 4, 'S', 423.0, 365.89500522613525)\n",
            "('BOLLERIA', 'VENTA', datetime.date(2021, 5, 1), None, '3880', 2.5910000801086426, 3, 'S', 285.0, 738.4349975585938)\n",
            "('BOLLERIA', 'VENTA', datetime.date(2021, 5, 1), None, '3960', 2.318000078201294, 1, 'S', 402.0, 931.835994720459)\n",
            "('PANADERIA', 'VENTA', datetime.date(2021, 5, 1), None, '417', 4.038000106811523, 5, 'S', 72.0, 290.7360038757324)\n",
            "\n",
            "✅ Verificación final completada\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "tablas = [\n",
        "    \"sandbox.articulos_top\",\n",
        "    \"sandbox.calendario_dias\",\n",
        "    \"sandbox.calendario_completo\",\n",
        "    \"sandbox.ventas_diarias\",\n",
        "]\n",
        "vistas = [\n",
        "    \"sandbox.ventas_diarias_estudio_completo\",\n",
        "    \"sandbox.ventas_diarias_estudio\",\n",
        "]\n",
        "\n",
        "with engine.connect() as con:\n",
        "    print(\"== Recuento de filas ==\")\n",
        "    for t in tablas:\n",
        "        n = con.execute(text(f\"SELECT COUNT(*) FROM {t};\")).scalar()\n",
        "        print(f\"✔ {t}: {n} filas\")\n",
        "\n",
        "    print(\"\\n== Esquema ventas_diarias ==\")\n",
        "    cols = [r[0] for r in con.execute(text(\"SHOW COLUMNS FROM sandbox.ventas_diarias;\")).fetchall()]\n",
        "    print(cols)\n",
        "\n",
        "    print(\"\\n== Resumen ventas_diarias ==\")\n",
        "    resumen = con.execute(text(\"\"\"\n",
        "        SELECT \n",
        "            MIN(fecha) AS min_fecha,\n",
        "            MAX(fecha) AS max_fecha,\n",
        "            COUNT(*)   AS filas,\n",
        "            COUNT(DISTINCT articulo) AS n_articulos,\n",
        "            SUM(cantidad) AS total_cantidad\n",
        "        FROM sandbox.ventas_diarias;\n",
        "    \"\"\")).mappings().one()\n",
        "    print(dict(resumen))\n",
        "\n",
        "    # --- Smoke tests ---\n",
        "    print(\"\\n== Smoke tests ==\")\n",
        "    # A) Consistencia exacta con base (VENTA y >0)\n",
        "    diff = con.execute(text(\"\"\"\n",
        "        WITH base AS (\n",
        "          SELECT DATE(FechaVenta) AS fecha, Articulo,\n",
        "                 SUM(CASE WHEN Cantidad > 0 THEN Cantidad ELSE 0 END) AS cant_base\n",
        "          FROM sandbox.rem_ventas\n",
        "          WHERE Tipo='VENTA'\n",
        "          GROUP BY 1,2\n",
        "        ), comp AS (\n",
        "          SELECT v.fecha, v.articulo, v.cantidad - b.cant_base AS d\n",
        "          FROM sandbox.ventas_diarias v\n",
        "          JOIN base b ON v.fecha=b.fecha AND v.articulo=b.articulo\n",
        "        )\n",
        "        SELECT COALESCE(SUM(d<>0),0) FROM comp;\n",
        "    \"\"\")).scalar()\n",
        "    assert diff == 0, f\"Diferencias base(>0) vs ventas_diarias: {diff}\"\n",
        "    print(\"✔ Consistencia con base (VENTA>0)\")\n",
        "\n",
        "    # B) Unicidad (fecha, articulo)\n",
        "    dups = con.execute(text(\"\"\"\n",
        "        SELECT COALESCE(COUNT(*) - COUNT(DISTINCT CONCAT_WS('|',fecha,articulo)),0)\n",
        "        FROM sandbox.ventas_diarias;\n",
        "    \"\"\")).scalar()\n",
        "    assert dups == 0, f\"Duplicados en ventas_diarias: {dups}\"\n",
        "    print(\"✔ Unicidad (fecha, articulo)\")\n",
        "\n",
        "    # C) No negativos\n",
        "    negs = con.execute(text(\"\"\"\n",
        "        SELECT COALESCE(SUM(cantidad<0),0) FROM sandbox.ventas_diarias;\n",
        "    \"\"\")).scalar()\n",
        "    assert negs == 0, \"Cantidades negativas en ventas_diarias\"\n",
        "    print(\"✔ Sin negativos\")\n",
        "\n",
        "    # Vistas: muestra 5 filas\n",
        "    print(\"\\n== Primeras filas de vistas ==\")\n",
        "    for v in vistas:\n",
        "        try:\n",
        "            rows = con.execute(text(f\"SELECT * FROM {v} LIMIT 5;\")).fetchall()\n",
        "            print(f\"\\n{v}:\")\n",
        "            for r in rows:\n",
        "                print(r)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠ No se pudo leer {v}: {e}\")\n",
        "\n",
        "print(\"\\n✅ Verificación final completada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nota sobre la ejecución de consultas SQL y el uso de SQLAlchemy\n",
        "\n",
        "Durante la preparación y carga de datos, he tenido que **dividir las consultas SQL en varias ejecuciones individuales** en vez de ejecutar todo el bloque de una vez. Esto se debe a que el driver `pymysql` de SQLAlchemy (que conecta con MySQL) no permite ejecutar varias sentencias (por ejemplo, DROP y CREATE) juntas en una sola llamada. Además, algunas sentencias complejas requieren ejecutarse de forma separada para evitar errores de sintaxis y problemas con el formateo de cadenas (especialmente cuando se usan funciones como `date_format` con `%`).\n",
        "\n",
        "**Sobre el uso de SQLAlchemy:**  \n",
        "He optado por usar SQLAlchemy por su flexibilidad y porque permite una gestión más profesional y portable de la conexión y las transacciones a la base de datos. Es cierto que, en algunos casos, el conector `mysql-connector-python` podría haber simplificado la ejecución de bloques largos de SQL, pero trabajar con SQLAlchemy me ha permitido aprender y aplicar buenas prácticas de desarrollo en proyectos de análisis de datos con Python.\n",
        "\n",
        "En resumen, aunque ejecutar las consultas una a una puede parecer menos eficiente al principio, garantiza que cada paso del proceso se controla y documenta correctamente, y me ha servido para entender mejor cómo interactúan Python y SQL en proyectos reales.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "panaderia-datathon",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
