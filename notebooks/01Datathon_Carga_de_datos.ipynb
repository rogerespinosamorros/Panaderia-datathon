{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de Datos - Panadería Salvador\n",
        "\n",
        "## 1. Carga inicial de datos\n",
        "\n",
        "En este primer notebook del proyecto, vamos a realizar la **carga de datos brutos** de la Panadería Salvador. El objetivo es importar los archivos originales (ventas, productos, clientes, etc.), realizar una primera inspección básica y dejar los datos listos para el análisis exploratorio y el modelado posterior.\n",
        "\n",
        "**Pasos de este notebook:**\n",
        "- Descripción breve de los datos disponibles.\n",
        "- Carga de los archivos originales al entorno de trabajo.\n",
        "- Comprobación inicial de la integridad y estructura de los datos.\n",
        "\n",
        "---\n",
        "\n",
        "> **Nota:** Todos los análisis, visualizaciones y modelos posteriores del proyecto partirán de esta carga inicial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ¿Por qué usamos SQLAlchemy y Polars?\n",
        "\n",
        "- **SQLAlchemy**: Permite conectar fácilmente a varias bases de datos y es más flexible y profesional que `mysql-connector-python`.\n",
        "- **Polars**: Es mucho más rápido y eficiente que pandas para el análisis y procesamiento de grandes volúmenes de datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA6CHl-SEYwd",
        "outputId": "95941d1e-8f15-4c68-a728-5fc7b3a9a4ee"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, text  # Función \"text\" para ejecutar consultas SQL\n",
        "import polars as pl  # He decidido probar Polars, por si es más rápido que Pandas\n",
        "from dotenv import load_dotenv  # Carga variables desde el archivo .env\n",
        "import os    # Módulo de Python para interactuar fácilmente con carpetas y archivos\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "# Parámetros de conexión a la base de datos\n",
        "user = os.getenv(\"DB_USER\")\n",
        "host= os.getenv(\"DB_HOST\")\n",
        "port = 3306  # Puerto por defecto de MySQL\n",
        "password= os.getenv(\"DB_PASSWORD\")\n",
        "nombre_base_datos = os.getenv(\"DB_NAME\")   \n",
        "\n",
        "# Crear el engine de SQLAlchemy\n",
        "engine = create_engine(\n",
        "    f\"mysql+pymysql://{user}:{password}@{host}:{port}/{nombre_base_datos}\"\n",
        ")\n",
        "\n",
        "# Comprobar si la conexión es válida\n",
        "try:\n",
        "    with engine.connect() as connection:\n",
        "        result = connection.execute(text(\"SELECT 1;\"))\n",
        "        print(\"Conexión exitosa\", result.fetchone())\n",
        "except Exception as e:\n",
        "    print(\"Error en la conexión:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  \n",
        "\n",
        "DATA_RAW_DIR = r\"d:\\PersonalProjects\\Panadería Datathon\\data\\raw\"\n",
        "\n",
        "# He usado fastexcel para leer archivos excel sin usar Pandas (por probar)\n",
        "df_ventas = pl.read_excel(os.path.join(DATA_RAW_DIR, \"ArticulosPanaderia.xlsx\"))\n",
        "df_calendario = pl.read_excel(os.path.join(DATA_RAW_DIR, \"Calendario.xlsx\"))\n",
        "df_pedidos = pl.read_excel(os.path.join(DATA_RAW_DIR, \"CantidadPedida.xlsx\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, Table, MetaData, Column, Integer, String, Float, Date\n",
        "\n",
        "metadata = MetaData()\n",
        "\n",
        "# Tabla de ventas\n",
        "rem_ventas = Table(\n",
        "    \"rem_ventas\", metadata,\n",
        "    Column(\"FAMILIA\", String(255)),\n",
        "    Column(\"Tipo\", String(255)),\n",
        "    Column(\"FechaVenta\", Date),\n",
        "    Column(\"HoraVenta\", Integer),\n",
        "    Column(\"Articulo\", String(255)),\n",
        "    Column(\"Cantidad\", Float),\n",
        "    Column(\"Precio\", Float),\n",
        "    Column(\"Importe\", Float),\n",
        ")\n",
        "\n",
        "# Tabla de calendario\n",
        "rem_calendario = Table(\n",
        "    \"rem_calendario\", metadata,\n",
        "    Column(\"Fecha\", Date),\n",
        "    Column(\"Festivo\", String(255)),\n",
        ")\n",
        "\n",
        "# Tabla de pedidos\n",
        "rem_pedidos = Table(\n",
        "    \"rem_pedidos\", metadata,\n",
        "    Column(\"Tipo\", String(255)),\n",
        "    Column(\"Fecha\", Date),\n",
        "    Column(\"Articulo\", String(255)),\n",
        "    Column(\"Cantidad\", Float),\n",
        "    Column(\"Precio\", Float),\n",
        "    Column(\"Importe\", Float),\n",
        ")\n",
        "\n",
        "metadata.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYW3bbG4F0um"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "from sqlalchemy import insert\n",
        "\n",
        "# Inserción por lotes, ya que da error de conexión la tabla ventas\n",
        "CHUNK_SIZE = 1000 # Muestra de 1000 registros\n",
        "\n",
        "def insertar_chunks(conn, tabla, df, nombre_tabla, chunk_size=CHUNK_SIZE):\n",
        "    registros = df.to_dicts() # Cada registro es un dict, ya que SQLAlchemy los mapea\n",
        "    total = len(registros)\n",
        "    for i in range(0, total, chunk_size):\n",
        "        lote = registros[i:i+chunk_size]\n",
        "        try:\n",
        "            conn.execute(insert(tabla), lote)\n",
        "            print(f\"Chunk {i//chunk_size+1} de {nombre_tabla} ({len(lote)} filas) insertado\")\n",
        "        except SQLAlchemyError as e:\n",
        "            print(f\"Error en chunk {i//chunk_size+1} de {nombre_tabla}: {e}\")\n",
        "            raise    # Aquí detiene la ejecución y muestra el error\n",
        "\n",
        "with engine.begin() as conn:\n",
        "    insertar_chunks(conn, rem_ventas, df_ventas, \"rem_ventas\")\n",
        "    insertar_chunks(conn, rem_calendario, df_calendario, \"rem_calendario\")\n",
        "    insertar_chunks(conn, rem_pedidos, df_pedidos, \"rem_pedidos\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inserción eficiente de datos: aprendiendo y experimentando\n",
        "\n",
        "En este  proyecto, he probado distintas formas de cargar grandes volúmenes de datos (como la tabla de ventas) en MySQL.  \n",
        "Finalmente, me he decantado por la inserción en lotes (*chunks*) usando Polars y SQLAlchemy, por varias razones:\n",
        "\n",
        "- **Simplicidad y limpieza**: El código es mucho más corto y claro, sin necesidad de recorrer filas una a una ni construir registros manualmente.\n",
        "- **Rendimiento**: La inserción por lotes evita errores de conexión y permite que la carga sea sorprendentemente rápida (la tabla ventas, que es la mayor, se ha cargado en solo 1 minuto y 40 segundos).\n",
        "- **Aprendizaje**: Creo que he conseguido mejorar el rendimiento al notebook original, trabajando de forma más eficiente con grandes conjuntos de datos y bases SQL en Python, experimentando con distintos tamaños de lote (*chunk size* o muestras más pequeñas).\n",
        "\n",
        "En resumen, experimentar con Polars y SQLAlchemy, junto con la inserción en *chunks*, me ha permitido cargar los datos de manera profesional, rápida y con un código más fácil de mantener.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nota: las consultas siguientes están preparadas para lanzarse con los datos cargados en la bbdd data y con los nombres iniciales, si se lanzan con usuario1 debe adaptarse\n",
        "\n",
        "#### Voy a intentar hacer las consultas con SQLAlchemy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dejo esto aquí, porqué he tenido problemas de conexión con el servidor, con esta celda compruebo si es error de SQL o de conexión\n",
        "from sqlalchemy import text\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"SELECT 1;\"))   # Una simple consulta para ver si funciona\n",
        "    print(result.fetchone())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# En vez de una sola consulta, voy a dividirlas en sentencias, aquí SQLAlchemy no es tan eficiente, detecta errores al hacer la consulta grande\n",
        "from sqlalchemy import text\n",
        "\n",
        "sentencia = \"\"\"\n",
        "drop table if exists sandbox.articulos_top;\n",
        "create table sandbox.articulos_top as (\n",
        "    select\n",
        "        Articulo,\n",
        "        FAMILIA,\n",
        "        sum(importe) as importe_total,\n",
        "        ROW_NUMBER () OVER(partition by FAMILIA order by sum(importe) desc) as orden\n",
        "    from sandbox.rem_ventas\n",
        "    where FechaVenta >= '2021-05-01'\n",
        "    group by 1,2\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    for stmt in sentencia.strip().split(';'):\n",
        "        if stmt.strip():\n",
        "            try:\n",
        "                conn.execute(text(stmt + ';'))\n",
        "                print(\"Sentencia ejecutada correctamente:\\n\", stmt[:100], \"...\")\n",
        "            except Exception as e:\n",
        "                print(\"Error ejecutando la sentencia:\\n\", stmt[:100], \"...\\n\", e)\n",
        "                raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "sentencia_drop = \"DROP TABLE IF EXISTS sandbox.calendario_dias;\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_drop))\n",
        "        print(\"DROP ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el DROP:\\n\", e)\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Me ha dado errores al realizar la siguiente sentencia, he descubierto que MySQL corta las CTEs recursivas tras 1000 iteraciones\n",
        "\n",
        "# Así que he tenido que aumentar el límite de iteraciones para los dias que hay entre 2017 y 2023\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(text(\"SET SESSION cte_max_recursion_depth = 4000;\"))\n",
        "    print(\"Límite de recursión aumentado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esta sentencia es la que fallaba constantemente al iterar más de 1000, en este caso días entre 2017 y 2023\n",
        "from sqlalchemy import text\n",
        "\n",
        "sentencia_create = \"\"\"\n",
        "CREATE TABLE sandbox.calendario_dias AS\n",
        "WITH RECURSIVE cte_calendario AS (\n",
        "    SELECT DATE('2017-01-01') AS calendar_date\n",
        "    UNION ALL\n",
        "    SELECT DATE_ADD(calendar_date, INTERVAL 1 DAY) AS calendar_date FROM cte_calendario\n",
        "    WHERE DATE_ADD(calendar_date, INTERVAL 1 DAY) <= DATE('2023-12-31')\n",
        ")\n",
        "SELECT\n",
        "    calendar_date AS fecha,\n",
        "    YEAR(calendar_date) AS fx_anno,\n",
        "    MONTH(calendar_date) AS fx_mes,\n",
        "    DAY(calendar_date) AS fx_day,\n",
        "    DATE_FORMAT(calendar_date, '%Y%m') AS fx_anno_mes,\n",
        "    DATE_FORMAT(calendar_Date, '%x-%v') AS semana\n",
        "FROM cte_calendario;\n",
        "\"\"\"\n",
        "\n",
        "print(sentencia_create)  # <-- revisa que solo hay %\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_create))\n",
        "        print(\"CREATE ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el CREATE:\\n\", e)\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "# DROP\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(\"DROP TABLE IF EXISTS sandbox.calendario_completo;\"))\n",
        "        print(\"DROP calendario_completo ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error en el DROP:\\n\", e)\n",
        "        raise\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE\n",
        "sentencia_create = \"\"\"\n",
        "CREATE TABLE sandbox.calendario_completo AS\n",
        "SELECT\n",
        "    base.*,\n",
        "    festivos.festivo\n",
        "FROM sandbox.calendario_dias base\n",
        "LEFT JOIN (\n",
        "    SELECT\n",
        "        a.*,\n",
        "        ROW_NUMBER() OVER(PARTITION BY a.fecha ORDER BY a.festivo) AS orden\n",
        "    FROM sandbox.rem_calendario a\n",
        ") festivos\n",
        "ON base.fecha = festivos.fecha\n",
        "AND festivos.orden = 1;\n",
        "\"\"\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_create))\n",
        "        print(\"CREATE calendario_completo ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el CREATE:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DROP\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(\"DROP TABLE IF EXISTS sandbox.ventas_diarias;\"))\n",
        "        print(\"DROP ventas_diarias ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error en el DROP:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE\n",
        "sentencia_create = \"\"\"\n",
        "CREATE TABLE sandbox.ventas_diarias AS\n",
        "SELECT\n",
        "    base.familia,\n",
        "    base.tipo,\n",
        "    base.fechaVenta,\n",
        "    calendario.festivo,\n",
        "    base.articulo,\n",
        "    SUM(base.precio * base.cantidad) / SUM(base.cantidad) AS precio,\n",
        "    articulos.orden AS orden_articulo_familia,\n",
        "    CASE WHEN base.fechaVenta >= DATE('2021-05-01') THEN 'S' ELSE 'N' END AS in_fecha_estudio,\n",
        "    SUM(base.cantidad) AS cantidad,\n",
        "    SUM(base.importe) AS importe\n",
        "FROM sandbox.rem_ventas base\n",
        "INNER JOIN sandbox.calendario_completo calendario\n",
        "    ON base.FechaVenta = calendario.fecha\n",
        "INNER JOIN sandbox.articulos_top articulos\n",
        "    ON base.familia = articulos.familia\n",
        "    AND base.articulo = articulos.articulo\n",
        "GROUP BY 1,2,3,4,5,7,8;\n",
        "\"\"\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_create))\n",
        "        print(\"CREATE ventas_diarias ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el CREATE:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DROP\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(\"DROP VIEW IF EXISTS sandbox.ventas_diarias_estudio_completo;\"))\n",
        "        print(\"DROP vista ventas_diarias_estudio_completo ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error en el DROP:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE\n",
        "sentencia_create = \"\"\"\n",
        "CREATE VIEW sandbox.ventas_diarias_estudio_completo AS\n",
        "SELECT *\n",
        "FROM sandbox.ventas_diarias\n",
        "WHERE tipo = 'VENTA'\n",
        "  AND in_fecha_estudio = 'S'\n",
        "  AND orden_articulo_familia <= 5;\n",
        "\"\"\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_create))\n",
        "        print(\"CREATE vista ventas_diarias_estudio_completo ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el CREATE VIEW:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DROP\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(\"DROP VIEW IF EXISTS sandbox.ventas_diarias_estudio;\"))\n",
        "        print(\"DROP vista ventas_diarias_estudio ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error en el DROP:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE\n",
        "sentencia_create = \"\"\"\n",
        "CREATE VIEW sandbox.ventas_diarias_estudio AS\n",
        "SELECT *\n",
        "FROM sandbox.ventas_diarias\n",
        "WHERE tipo = 'VENTA'\n",
        "  AND in_fecha_estudio = 'S'\n",
        "  AND fechaventa < DATE('2023-05-01')\n",
        "  AND orden_articulo_familia <= 5;\n",
        "\"\"\"\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    try:\n",
        "        conn.execute(text(sentencia_create))\n",
        "        print(\"CREATE vista ventas_diarias_estudio ejecutado correctamente\")\n",
        "    except Exception as e:\n",
        "        print(\"Error ejecutando el CREATE VIEW:\\n\", e)\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pequeña comprobación para ver que las nuevas tablas existen y contienen datos\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    result = conn.exec_driver_sql(\"SELECT COUNT(*) FROM sandbox.ventas_diarias;\")\n",
        "    print(\"Filas en ventas_diarias:\", result.fetchone()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiEfBfVOB_ik"
      },
      "outputs": [],
      "source": [
        "# Comprobación que las tablas estan correctas y recuento de filas\n",
        "from sqlalchemy import text\n",
        "\n",
        "tablas_a_comprobar = [\n",
        "    \"sandbox.articulos_top\",\n",
        "    \"sandbox.calendario_dias\",\n",
        "    \"sandbox.calendario_completo\",\n",
        "    \"sandbox.ventas_diarias\"\n",
        "]\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    for tabla in tablas_a_comprobar:\n",
        "        try:\n",
        "            result = conn.execute(text(f\"SELECT COUNT(*) FROM {tabla};\"))\n",
        "            n_filas = result.scalar()\n",
        "            print(f\"✔ {tabla}: {n_filas} filas\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error comprobando {tabla}:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5EqkZR34k2I"
      },
      "outputs": [],
      "source": [
        "# Comprobar vistas y primeras filas\n",
        "\n",
        "vistas_a_comprobar = [\n",
        "    \"sandbox.ventas_diarias_estudio_completo\",\n",
        "    \"sandbox.ventas_diarias_estudio\"\n",
        "]\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    for vista in vistas_a_comprobar:\n",
        "        try:\n",
        "            result = conn.execute(text(f\"SELECT * FROM {vista} LIMIT 5;\"))\n",
        "            filas = result.fetchall()\n",
        "            print(f\"\\n✔ {vista} (primeras 5 filas):\")\n",
        "            for fila in filas:\n",
        "                print(fila)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error comprobando {vista}:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar nombres de columnas\n",
        "from sqlalchemy import text\n",
        "\n",
        "tabla = \"sandbox.ventas_diarias\"\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(f\"SHOW COLUMNS FROM {tabla};\"))\n",
        "    columnas = [row[0] for row in result.fetchall()]\n",
        "    print(f\"Columnas en {tabla}:\", columnas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nota sobre la ejecución de consultas SQL y el uso de SQLAlchemy\n",
        "\n",
        "Durante la preparación y carga de datos, he tenido que **dividir las consultas SQL en varias ejecuciones individuales** en vez de ejecutar todo el bloque de una vez. Esto se debe a que el driver `pymysql` de SQLAlchemy (que conecta con MySQL) no permite ejecutar varias sentencias (por ejemplo, DROP y CREATE) juntas en una sola llamada. Además, algunas sentencias complejas requieren ejecutarse de forma separada para evitar errores de sintaxis y problemas con el formateo de cadenas (especialmente cuando se usan funciones como `date_format` con `%`).\n",
        "\n",
        "**Sobre el uso de SQLAlchemy:**  \n",
        "He optado por usar SQLAlchemy por su flexibilidad y porque permite una gestión más profesional y portable de la conexión y las transacciones a la base de datos. Es cierto que, en algunos casos, el conector `mysql-connector-python` podría haber simplificado la ejecución de bloques largos de SQL, pero trabajar con SQLAlchemy me ha permitido aprender y aplicar buenas prácticas de desarrollo en proyectos de análisis de datos con Python.\n",
        "\n",
        "En resumen, aunque ejecutar las consultas una a una puede parecer menos eficiente al principio, garantiza que cada paso del proceso se controla y documenta correctamente, y me ha servido para entender mejor cómo interactúan Python y SQL en proyectos reales.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "panaderia-datathon",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
