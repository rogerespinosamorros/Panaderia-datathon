# ‚úÖ Modelos finales para productos problem√°ticos

Este documento resume las decisiones de modelado para los productos con peores resultados iniciales de regresi√≥n (basado en MAPE).

---

## üîπ Producto 6425
- Modelo final: RandomForestClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.77
- Umbral ajustado: No necesario (buenos resultados iniciales)

---

## üîπ Producto 5403
- Modelo final: RandomForestClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.84
- Umbral ajustado: No necesario

---

## üîπ Producto 5404
- Modelo final: RandomForestClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.79
- Umbral ajustado: No necesario

---

## üîπ Producto 6451
- Modelo final: XGBClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.66
- Umbral ajustado: ‚úÖ 0.31 (√≥ptimo seg√∫n F1)

---

## üîπ Producto 6523
- Modelo final: XGBClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.64
- Umbral ajustado: ‚úÖ 0.40

---

## üîπ Producto 6549
- Modelo final: XGBClassifier
- Clasificaci√≥n: Binaria
- Accuracy: 0.72
- Umbral ajustado: ‚úÖ 0.27

---

 Observaciones
- Los productos m√°s ca√≥ticos obtuvieron mejores resultados con clasificaci√≥n binaria.
- Se aplic√≥ balance de clases (`scale_pos_weight`) y ajuste de umbral manual para mejorar recall en clase 1 (alta demanda).

## ‚úÖ Producto 417 


Clasificaci√≥n **binaria** de la demanda como:
- `0`: Demanda normal o baja (‚â§ 1000 unidades)
- `1`: Demanda alta (> 1000 unidades)

---


**GradientBoostingClassifier** (scikit-learn), dentro de un `Pipeline` con:

- Preprocesador (`ColumnTransformer`) que incluye:
  - Escalado y media para variables num√©ricas
  - One-hot encoding para variables categ√≥ricas

No se utiliz√≥ `class_weight` porque no mejoraba los resultados.

---

 **Variables utilizadas
- `precio`
- `dia_semana` (0-6)
- `mes` (1-12)
- `is_weekend`
- `is_start_of_month`
- `cantidad_lag1`, `cantidad_lag2`, `cantidad_lag3`
- `rolling_mean_3`, `rolling_std_3`
- `diff_lag1_lag2` (lag1 - lag2)

---

 üìä M√©tricas finales (validaci√≥n con TimeSeriesSplit, 3 folds)

| Clase        | Precision | Recall | F1-score | Soporte promedio |
|--------------|-----------|--------|----------|------------------|
| No alta (0)  | 0.645     | 0.720  | 0.664    | 8.67             |
| Alta (1)     | 0.625     | 0.379  | 0.408    | 5.33             |
| **Accuracy** |           |        | **59.5%**|                  |

---

 üóÉÔ∏è Notas para MLflow
- Guardar el pipeline completo (`preprocessor + GradientBoostingClassifier`)
- Registrar `model_input_schema` con las 11 features listadas
- Usar `target_name = 'clase_binaria'`
- Umbral de conversi√≥n a binario: `cantidad > 1000`

---

## Producto 900

## ‚öôÔ∏è Configuraci√≥n del experimento

- **Modelo:** `ExtraTreesClassifier` (`class_weight='balanced'`)
- **Validaci√≥n:** `TimeSeriesSplit(n_splits=5)`
- **Target binarizado:**  
  - Umbral en el **percentil 60** de `cantidad`
  - `clase_demanda = (cantidad > cantidad.quantile(0.6)).astype(int)`
- **Features utilizadas:**
  - `precio`
  - `dia_semana`
  - `mes`
  - `festivo` (convertido a 0/1)
  - `cantidad_lag1`
  - `cantidad_lag2`
  - `cantidad_lag3`
- **Preprocesamiento:**
  - Num√©ricas: imputaci√≥n por media + escalado
  - Categ√≥ricas: imputaci√≥n por moda + one-hot encoding